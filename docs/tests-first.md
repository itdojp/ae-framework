# Tests-First Intent Mode

> **ğŸŒ Language / è¨€èª**: [English](#english) | [æ—¥æœ¬èª](#japanese)

---

## English

This guide describes the **tests-first** workflow proposed in #1067: generate tests immediately after intent capture, then **rank code candidates** by how well they satisfy those tests.

### Goals

- Make `ae tests:suggest` the default step after intent capture.
- Use `ae code:rank-by-tests` to select the best code candidate based on test outcomes.
- Provide starter prompts for common domains to reduce prompt variance.

### Workflow

1. **Intent**: Capture user requirements in natural language.
2. **Tests**: Generate tests that represent the intent.
3. **Candidates**: Produce multiple code candidates.
4. **Rank**: Run tests against each candidate and score them.
5. **Select**: Pick the top-ranked candidate and continue the pipeline.

### Ranking Heuristics (initial proposal)

```
score = pass_rate
      - flake_penalty
      - runtime_penalty

pass_rate       = passed_tests / total_tests
flake_penalty   = flake_count * 0.02
runtime_penalty = min(runtime_ms / 60000, 0.2)
```

Notes:
- Penalize flaky tests explicitly to avoid unstable selections.
- Cap runtime penalty to avoid over-penalizing complex suites.
- Adjust weights per project constraints (CI vs local).

### Templates

Starter prompts live in `templates/prompts/`:
- `templates/prompts/tests-first-http-api.md`
- `templates/prompts/tests-first-queue.md`
- `templates/prompts/tests-first-auth.md`
- `templates/prompts/tests-first-math.md`

Use these as baseline prompts for test generation to keep outputs consistent across runs.

### Next Steps

- Wire `ae tests:suggest` as the default route in the 6-phase docs and CLI.
- Implement `ae code:rank-by-tests` using the scoring heuristic above.
- Add optional `--autofix` flow to patch failing tests and re-rank.

---

## Japanese

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€#1067 ã§ææ¡ˆã™ã‚‹ **tests-first** ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆIntent ç›´å¾Œã«ãƒ†ã‚¹ãƒˆç”Ÿæˆã—ã€ãƒ†ã‚¹ãƒˆçµæœã§ã‚³ãƒ¼ãƒ‰å€™è£œã‚’å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹æ–¹å¼ï¼‰ã‚’æ•´ç†ã—ã¾ã™ã€‚

### ç›®çš„

- `ae tests:suggest` ã‚’ Intent ç›´å¾Œã®æ¨™æº–ã‚¹ãƒ†ãƒƒãƒ—ã«ã™ã‚‹ã€‚
- `ae code:rank-by-tests` ã§ãƒ†ã‚¹ãƒˆçµæœã«åŸºã¥ãæœ€é©å€™è£œã‚’é¸ã¶ã€‚
- ä»£è¡¨ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé››å½¢ã§å‡ºåŠ›ã®ã°ã‚‰ã¤ãã‚’æŠ‘ãˆã‚‹ã€‚

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

1. **Intent**: è¦ä»¶ã‚’è‡ªç„¶è¨€èªã§å–å¾—ã€‚
2. **Tests**: Intent ã‚’è¡¨ã™ãƒ†ã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
3. **Candidates**: è¤‡æ•°ã®ã‚³ãƒ¼ãƒ‰å€™è£œã‚’ç”Ÿæˆã€‚
4. **Rank**: å€™è£œã”ã¨ã«ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ã‚¹ã‚³ã‚¢åŒ–ã€‚
5. **Select**: æœ€ä¸Šä½ã‚’æ¡ç”¨ã—å¾Œç¶šå·¥ç¨‹ã¸ã€‚

### ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ï¼ˆåˆæœŸæ¡ˆï¼‰

```
score = pass_rate
      - flake_penalty
      - runtime_penalty

pass_rate       = passed_tests / total_tests
flake_penalty   = flake_count * 0.02
runtime_penalty = min(runtime_ms / 60000, 0.2)
```

æ³¨è¨˜:
- ãƒ•ãƒ¬ãƒ¼ã‚¯ã¯æ˜ç¤ºçš„ã«æ¸›ç‚¹ã—ã€å®‰å®šæ€§ã‚’å„ªå…ˆã™ã‚‹ã€‚
- å®Ÿè¡Œæ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£ã¯ä¸Šé™ã‚’è¨­ã‘ã€è¤‡é›‘ç³»ã®éå‰°æ¸›ç‚¹ã‚’å›é¿ã™ã‚‹ã€‚
- CI/ãƒ­ãƒ¼ã‚«ãƒ«ãªã©åˆ¶ç´„ã«å¿œã˜ã¦é‡ã¿ã‚’èª¿æ•´ã™ã‚‹ã€‚

### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

`templates/prompts/` é…ä¸‹ã®é››å½¢ã‚’åˆ©ç”¨:
- `templates/prompts/tests-first-http-api.md`
- `templates/prompts/tests-first-queue.md`
- `templates/prompts/tests-first-auth.md`
- `templates/prompts/tests-first-math.md`

ãƒ†ã‚¹ãƒˆç”Ÿæˆã®åŸºæº–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦åˆ©ç”¨ã—ã€å‡ºåŠ›ã®ä¸€è²«æ€§ã‚’é«˜ã‚ã¾ã™ã€‚

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- 6 ç›¸ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ CLI ã®æ—¢å®šã‚’ `ae tests:suggest` ã«æ›´æ–°ã€‚
- `ae code:rank-by-tests` ã‚’ä¸Šè¨˜ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§å®Ÿè£…ã€‚
- å¤±æ•—ãƒ†ã‚¹ãƒˆä¿®æ­£ã«å‘ã‘ãŸ `--autofix` ã‚’è¿½åŠ ã€‚
