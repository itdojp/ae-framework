# AE Framework Benchmark Integration

## ğŸŒ Language / è¨€èª
[English](#english) | [æ—¥æœ¬èª](#japanese)

---

## English

### Overview

The AE Framework Benchmark Integration provides comprehensive performance evaluation against the [Req2Run-Benchmark](https://github.com/itdojp/req2run-benchmark) dataset. This system measures the framework's ability to transform requirements into executable applications across multiple dimensions.

### Features

- **Comprehensive Evaluation**: Tests functional coverage, performance, code quality, and security
- **35+ Problems**: Covers 16+ categories from web APIs to distributed systems
- **4 Difficulty Levels**: Basic â†’ Intermediate â†’ Advanced â†’ Expert
- **Automated Scoring**: Weighted metrics with customizable thresholds
- **Parallel Execution**: Configurable concurrency for faster benchmarking
- **Rich Reporting**: JSON, HTML, Markdown outputs with dashboard visualization

### Quick Start

#### Installation

The benchmark system is integrated into AE Framework:

```bash
# Install AE Framework with benchmark capabilities
pnpm add ae-framework

# Or build from source
pnpm run build:cli
```

#### Basic Usage

```bash
# List available benchmark problems
ae-benchmark list

# Run basic difficulty problems
ae-benchmark run --difficulty basic

# Run specific problems
ae-benchmark run --problems web-api-basic-001 cli-tool-basic-001

# Generate configuration template
ae-benchmark init --output benchmark-config.json

# Run with custom configuration
ae-benchmark run --config benchmark-config.json
```

#### Scripts

```bash
# Quick benchmark execution
pnpm run benchmark:basic

# CI-optimized run
pnpm run benchmark:ci

# List problems
pnpm run benchmark:list

# Generate config
pnpm run benchmark:init
```

### Configuration

#### Default Configuration

The system provides sensible defaults for different use cases:

```typescript
import { 
  DEFAULT_BENCHMARK_CONFIG,
  getConfigForDifficulty,
  getCIConfig 
} from './src/benchmark/req2run/config/default.js';

// Basic configuration
const basicConfig = getConfigForDifficulty(DifficultyLevel.BASIC);

// CI configuration
const ciConfig = getCIConfig();
```

#### Custom Configuration

Create a `benchmark-config.json` file:

```json
{
  "problems": [
    {
      "id": "web-api-basic-001",
      "enabled": true,
      "timeoutMs": 300000,
      "retries": 1,
      "category": "web-api",
      "difficulty": "basic"
    }
  ],
  "execution": {
    "parallel": false,
    "maxConcurrency": 2,
    "resourceLimits": {
      "maxMemoryMB": 4096,
      "maxCpuPercent": 80,
      "maxExecutionTimeMs": 3600000
    }
  },
  "evaluation": {
    "weights": {
      "functional": 0.35,
      "performance": 0.15,
      "quality": 0.20,
      "security": 0.15,
      "testing": 0.15
    },
    "thresholds": {
      "minOverallScore": 60,
      "minFunctionalCoverage": 70,
      "maxResponseTime": 2000
    }
  }
}
```

### Architecture

#### AE Framework Pipeline Integration

The benchmark system integrates with all 6 AE Framework phases:

```typescript
class Req2RunBenchmarkRunner {
  async runBenchmark(problemId: string): Promise<BenchmarkResult> {
    // Phase 1: Intent Analysis
    const intent = await this.intentAgent.analyze(spec);
    
    // Phase 2: Requirements Processing
    const requirements = await this.nlpAgent.process(intent);
    
    // Phase 3: User Stories Generation
    const userStories = await this.storiesAgent.generate(requirements);
    
    // Phase 4: Validation
    const validation = await this.validationAgent.verify(userStories);
    
    // Phase 5: Domain Modeling
    const domainModel = await this.domainAgent.model(validation);
    
    // Phase 6: UI/UX Generation
    const application = await this.uiAgent.generate(domainModel);
    
    return await this.evaluateResult(application, spec);
  }
}
```

#### Metrics Collection

The system collects comprehensive metrics:

```typescript
interface BenchmarkMetrics {
  overallScore: number;              // 0-100 total score
  functionalCoverage: number;        // % of requirements met
  testPassRate: number;              // % of tests passing
  performance: PerformanceMetrics;   // Response time, throughput
  codeQuality: QualityMetrics;       // Complexity, maintainability
  security: SecurityMetrics;         // Vulnerabilities, compliance
  timeToCompletion: number;          // Total execution time
  resourceUsage: ResourceMetrics;    // Memory, CPU usage
  phaseMetrics: PhaseMetrics[];      // Per-phase performance
}
```

### Problem Categories

The benchmark covers diverse problem types:

- **Web APIs**: REST services, GraphQL endpoints
- **CLI Tools**: Command-line utilities, data processors
- **Data Processing**: ETL pipelines, transformations
- **Cryptography**: Encryption, hashing, digital signatures
- **Network Protocols**: Custom protocols, servers
- **Authentication**: OAuth, JWT, session management
- **Databases**: Schema design, query optimization
- **Machine Learning**: Model training, inference pipelines
- **Distributed Systems**: Microservices, message queues
- **Real-time Systems**: WebSocket, streaming data

### Scoring Algorithm

The weighted scoring system considers multiple factors:

```
Overall Score = (
  Functional Coverage Ã— 0.35 +
  Performance Score Ã— 0.15 +
  Code Quality Score Ã— 0.20 +
  Security Score Ã— 0.15 +
  Testing Score Ã— 0.15
) Ã— Penalty Adjustments + Bonuses
```

#### Penalty System
- **Timeout Penalty**: 50% reduction for timeouts
- **Error Penalty**: 30% reduction for runtime errors
- **Quality Penalty**: 20% reduction for quality issues

#### Bonus System
- **Performance Bonus**: +10% for exceptional performance
- **Quality Bonus**: +10% for excellent code quality
- **Security Bonus**: +5% for perfect security compliance

### Reporting and Visualization

#### Available Formats
- **JSON**: Machine-readable results for CI/CD
- **HTML**: Rich interactive reports
- **Markdown**: Documentation-friendly summaries
- **CSV**: Spreadsheet analysis

#### Dashboard Features
- Real-time execution monitoring
- Historical trend analysis
- Category performance breakdown
- Resource usage visualization
- Comparison with baseline metrics

### CI/CD Integration

#### GitHub Actions

```yaml
name: Benchmark Evaluation
on:
  push:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm run benchmark:ci
      - uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: reports/benchmark/
```

#### Performance Regression Detection

The system automatically detects performance regressions:

```bash
# Compare with baseline
ae-benchmark run --baseline ./baseline-results.json

# Set failure thresholds
ae-benchmark run --fail-on-regression 10%
```

### Troubleshooting

#### Common Issues

1. **Timeout Errors**
   ```bash
   # Increase timeout for complex problems
   ae-benchmark run --timeout 600000  # 10 minutes
   ```

2. **Memory Limitations**
   ```bash
   # Adjust memory limits
   ae-benchmark run --config config-high-memory.json
   ```

3. **Docker Issues**
   ```bash
   # Disable Docker isolation for debugging
   ae-benchmark run --no-docker
   ```

#### Debug Mode

```bash
# Enable verbose logging
DEBUG=ae-framework:benchmark ae-benchmark run

# Save intermediate artifacts
ae-benchmark run --save-artifacts ./debug-artifacts/
```

### Performance Optimization

#### Best Practices

1. **Start with Basic Problems**: Validate setup with simple cases
2. **Use Parallel Execution**: Enable for multiple problems
3. **Resource Monitoring**: Watch memory/CPU usage
4. **Incremental Testing**: Add complexity gradually

#### Resource Management

```typescript
// Configure resource limits
const config = {
  execution: {
    resourceLimits: {
      maxMemoryMB: 4096,      // 4GB limit
      maxCpuPercent: 80,      // 80% CPU limit
      maxExecutionTimeMs: 3600000  // 1 hour timeout
    }
  }
};
```

### Contributing

#### Adding New Problems

1. Fork the [req2run-benchmark](https://github.com/itdojp/req2run-benchmark) repository
2. Add problem specification following the schema
3. Update problem registry in AE Framework
4. Submit pull request with test results

#### Extending Evaluation Metrics

```typescript
// Custom metric evaluator
class CustomEvaluator implements MetricEvaluator {
  async evaluate(application: any, spec: RequirementSpec): Promise<number> {
    // Custom evaluation logic
    return score;
  }
}
```

---

## æ—¥æœ¬èª

### æ¦‚è¦

AE Frameworkãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±åˆã¯ã€[Req2Run-Benchmark](https://github.com/itdojp/req2run-benchmark)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹åŒ…æ‹¬çš„ãªæ€§èƒ½è©•ä¾¡ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¦æ±‚ä»•æ§˜ã‹ã‚‰å®Ÿè¡Œå¯èƒ½ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®å¤‰æ›èƒ½åŠ›ã‚’å¤šè§’çš„ã«æ¸¬å®šã—ã¾ã™ã€‚

### ç‰¹å¾´

- **åŒ…æ‹¬çš„è©•ä¾¡**: æ©Ÿèƒ½ã‚«ãƒãƒ¬ãƒƒã‚¸ã€æ€§èƒ½ã€ã‚³ãƒ¼ãƒ‰å“è³ªã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’ãƒ†ã‚¹ãƒˆ
- **35+å•é¡Œ**: Web APIã‹ã‚‰åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã¾ã§16+ã‚«ãƒ†ã‚´ãƒªã‚’ã‚«ãƒãƒ¼
- **4é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«**: Basic â†’ Intermediate â†’ Advanced â†’ Expert
- **è‡ªå‹•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°**: ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªé–¾å€¤ã‚’æŒã¤é‡ã¿ä»˜ããƒ¡ãƒˆãƒªã‚¯ã‚¹
- **ä¸¦åˆ—å®Ÿè¡Œ**: é«˜é€Ÿãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãŸã‚ã®è¨­å®šå¯èƒ½ãªä¸¦è¡Œæ€§
- **è±Šå¯Œãªãƒ¬ãƒãƒ¼ãƒˆ**: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å¯è¦–åŒ–ä»˜ãã®JSONã€HTMLã€Markdownå‡ºåŠ›

### ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

#### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ã¯AE Frameworkã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ï¼š

```bash
# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ©Ÿèƒ½ä»˜ãAE Frameworkã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pnpm add ae-framework

# ã¾ãŸã¯ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ“ãƒ«ãƒ‰
pnpm run build:cli
```

#### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```bash
# åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å•é¡Œã‚’ãƒªã‚¹ãƒˆ
ae-benchmark list

# åŸºæœ¬é›£æ˜“åº¦å•é¡Œã‚’å®Ÿè¡Œ
ae-benchmark run --difficulty basic

# ç‰¹å®šã®å•é¡Œã‚’å®Ÿè¡Œ
ae-benchmark run --problems web-api-basic-001 cli-tool-basic-001

# è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ
ae-benchmark init --output benchmark-config.json

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§å®Ÿè¡Œ
ae-benchmark run --config benchmark-config.json
```

#### NPMã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
# ã‚¯ã‚¤ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
pnpm run benchmark:basic

# CIæœ€é©åŒ–å®Ÿè¡Œ
pnpm run benchmark:ci

# å•é¡Œãƒªã‚¹ãƒˆ
pnpm run benchmark:list

# è¨­å®šç”Ÿæˆ
pnpm run benchmark:init
```

### è¨­å®š

#### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š

ã‚·ã‚¹ãƒ†ãƒ ã¯æ§˜ã€…ãªç”¨é€”ã«å¯¾å¿œã™ã‚‹é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æä¾›ã—ã¾ã™ï¼š

```typescript
import { 
  DEFAULT_BENCHMARK_CONFIG,
  getConfigForDifficulty,
  getCIConfig 
} from './src/benchmark/req2run/config/default.js';

// åŸºæœ¬è¨­å®š
const basicConfig = getConfigForDifficulty(DifficultyLevel.BASIC);

// CIè¨­å®š
const ciConfig = getCIConfig();
```

#### ã‚«ã‚¹ã‚¿ãƒ è¨­å®š

`benchmark-config.json`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```json
{
  "problems": [
    {
      "id": "web-api-basic-001",
      "enabled": true,
      "timeoutMs": 300000,
      "retries": 1,
      "category": "web-api",
      "difficulty": "basic"
    }
  ],
  "execution": {
    "parallel": false,
    "maxConcurrency": 2,
    "resourceLimits": {
      "maxMemoryMB": 4096,
      "maxCpuPercent": 80,
      "maxExecutionTimeMs": 3600000
    }
  }
}
```

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

#### AE Frameworkãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ã¯AE Frameworkã®å…¨6ãƒ•ã‚§ãƒ¼ã‚ºã¨çµ±åˆã•ã‚Œã¾ã™ï¼š

```typescript
class Req2RunBenchmarkRunner {
  async runBenchmark(problemId: string): Promise<BenchmarkResult> {
    // ãƒ•ã‚§ãƒ¼ã‚º1: æ„å›³åˆ†æ
    const intent = await this.intentAgent.analyze(spec);
    
    // ãƒ•ã‚§ãƒ¼ã‚º2: è¦æ±‚å‡¦ç†
    const requirements = await this.nlpAgent.process(intent);
    
    // ãƒ•ã‚§ãƒ¼ã‚º3: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ç”Ÿæˆ
    const userStories = await this.storiesAgent.generate(requirements);
    
    // ãƒ•ã‚§ãƒ¼ã‚º4: æ¤œè¨¼
    const validation = await this.validationAgent.verify(userStories);
    
    // ãƒ•ã‚§ãƒ¼ã‚º5: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
    const domainModel = await this.domainAgent.model(validation);
    
    // ãƒ•ã‚§ãƒ¼ã‚º6: UI/UXç”Ÿæˆ
    const application = await this.uiAgent.generate(domainModel);
    
    return await this.evaluateResult(application, spec);
  }
}
```

### å•é¡Œã‚«ãƒ†ã‚´ãƒª

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å¤šæ§˜ãªå•é¡Œã‚¿ã‚¤ãƒ—ã‚’ã‚«ãƒãƒ¼ã—ã¾ã™ï¼š

- **Web API**: RESTã‚µãƒ¼ãƒ“ã‚¹ã€GraphQLã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- **CLIãƒ„ãƒ¼ãƒ«**: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†
- **ãƒ‡ãƒ¼ã‚¿å‡¦ç†**: ETLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€å¤‰æ›å‡¦ç†
- **æš—å·åŒ–**: æš—å·åŒ–ã€ãƒãƒƒã‚·ãƒ¥åŒ–ã€ãƒ‡ã‚¸ã‚¿ãƒ«ç½²å
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒ­ãƒˆã‚³ãƒ«**: ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€ã‚µãƒ¼ãƒãƒ¼
- **èªè¨¼**: OAuthã€JWTã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆã€ã‚¯ã‚¨ãƒªæœ€é©åŒ–
- **æ©Ÿæ¢°å­¦ç¿’**: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã€æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- **åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ **: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ã‚¹ãƒ†ãƒ **: WebSocketã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿

### ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¯è¤‡æ•°ã®è¦å› ã‚’è€ƒæ…®ã—ã¾ã™ï¼š

```
ç·åˆã‚¹ã‚³ã‚¢ = (
  æ©Ÿèƒ½ã‚«ãƒãƒ¬ãƒƒã‚¸ Ã— 0.35 +
  æ€§èƒ½ã‚¹ã‚³ã‚¢ Ã— 0.15 +
  ã‚³ãƒ¼ãƒ‰å“è³ªã‚¹ã‚³ã‚¢ Ã— 0.20 +
  ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ Ã— 0.15 +
  ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ Ã— 0.15
) Ã— ãƒšãƒŠãƒ«ãƒ†ã‚£èª¿æ•´ + ãƒœãƒ¼ãƒŠã‚¹
```

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼**
   ```bash
   # è¤‡é›‘ãªå•é¡Œã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å¢—åŠ 
   ae-benchmark run --timeout 600000  # 10åˆ†
   ```

2. **ãƒ¡ãƒ¢ãƒªåˆ¶é™**
   ```bash
   # ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’èª¿æ•´
   ae-benchmark run --config config-high-memory.json
   ```

#### ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰

```bash
# è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–
DEBUG=ae-framework:benchmark ae-benchmark run

# ä¸­é–“æˆæœç‰©ã‚’ä¿å­˜
ae-benchmark run --save-artifacts ./debug-artifacts/
```

### ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

#### æ–°ã—ã„å•é¡Œã®è¿½åŠ 

1. [req2run-benchmark](https://github.com/itdojp/req2run-benchmark)ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. ã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦å•é¡Œä»•æ§˜ã‚’è¿½åŠ 
3. AE Frameworkã®å•é¡Œãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚’æ›´æ–°
4. ãƒ†ã‚¹ãƒˆçµæœä»˜ãã®ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æå‡º

---

**é–¢é€£ãƒªãƒ³ã‚¯ / Related Links:**
- [Req2Run-Benchmark Repository](https://github.com/itdojp/req2run-benchmark)
- [Issue #155: Benchmark Integration](https://github.com/itdojp/ae-framework/issues/155)
- [AE Framework Documentation](../README.md)
