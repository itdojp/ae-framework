/**
 * Tests for Phase 3.3 Monitoring System
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { PerformanceMonitor } from '../../src/optimization/monitoring/performance-monitor.js';
import { MetricsCollector } from '../../src/optimization/monitoring/metrics-collector.js';
import { AlertManager } from '../../src/optimization/monitoring/alert-manager.js';
import { MonitoringSystem } from '../../src/optimization/monitoring/index.js';

describe('Performance Monitor', () => {
  let monitor: PerformanceMonitor;

  beforeEach(() => {
    monitor = new PerformanceMonitor({
      interval: 100, // Fast interval for testing
      thresholds: {
        cpu: { warning: 50, critical: 80 },
        memory: { warning: 60, critical: 90 },
        responseTime: { warning: 500, critical: 1000 },
        errorRate: { warning: 2, critical: 5 }
      }
    });
  });

  afterEach(() => {
    monitor.stop();
  });

  it('should start and stop monitoring', () => {
    expect(monitor.getCurrentMetrics()).toBeNull();
    
    monitor.start();
    expect(monitor.getCurrentMetrics()).toBeNull(); // No metrics yet
    
    monitor.stop();
  });

  it('should track operations and calculate response times', async () => {
    const startTime = performance.now();
    
    // Simulate operation
    await new Promise(resolve => setTimeout(resolve, 50));
    
    monitor.trackOperation('test-operation', startTime);
    
    // Start monitoring to collect metrics
    monitor.start();
    
    // Wait for initial metrics collection cycle
    await new Promise(resolve => setTimeout(resolve, 250));
    
    const metrics = monitor.getCurrentMetrics();
    expect(metrics).toBeTruthy();
    
    // Check response time tracking
    const responseTime = metrics?.responseTime;
    if (responseTime) {
      expect(responseTime.samples.length).toBeGreaterThan(0);
    } else {
      // If no metrics collected yet, check that operation was tracked
      expect(monitor.getCurrentMetrics()).toBeTruthy();
    }
  });

  it('should track errors', () => {
    monitor.trackError('validation-error');
    monitor.trackError('network-error');
    monitor.trackError('validation-error');
    
    monitor.start();
    
    // Errors should be tracked in metrics when collected
    expect(() => monitor.trackError('test-error')).not.toThrow();
  });

  it('should emit events for metrics collection', (done) => {
    monitor.on('metricsCollected', (metrics) => {
      expect(metrics).toBeTruthy();
      expect(metrics.timestamp).toBeInstanceOf(Date);
      expect(metrics.cpuUsage).toBeTruthy();
      expect(metrics.memoryUsage).toBeTruthy();
      done();
    });

    monitor.start();
  });

  it('should generate alerts for threshold violations', (done) => {
    let alertCount = 0;
    
    monitor.on('performanceAlert', (alert) => {
      alertCount++;
      expect(alert.type).toMatch(/warning|critical/);
      expect(alert.category).toBeTruthy();
      expect(alert.threshold).toBeGreaterThan(0);
      
      if (alertCount >= 1) {
        done();
      }
    });

    // Create high response times to trigger alerts
    for (let i = 0; i < 10; i++) {
      monitor.trackOperation('slow-operation', performance.now() - 2000); // 2 second operation
    }

    monitor.start();
  });
});

describe('Metrics Collector', () => {
  let collector: MetricsCollector;

  beforeEach(() => {
    collector = new MetricsCollector({
      interval: 100, // Fast aggregation for testing
      functions: ['avg', 'max', 'min'],
      retention: 60000 // 1 minute retention
    });
  });

  afterEach(() => {
    collector.stop();
  });

  it('should start and stop collection', () => {
    collector.start();
    expect(() => collector.stop()).not.toThrow();
  });

  it('should record individual metrics', () => {
    collector.recordMetric('test.counter', 10, { source: 'test' }, '', 'counter');
    collector.recordMetric('test.gauge', 75.5, { component: 'cpu' }, '%', 'gauge');
    
    const allMetrics = collector.getAllMetrics();
    expect(allMetrics.size).toBe(2);
    expect(allMetrics.has('test.counter')).toBe(true);
    expect(allMetrics.has('test.gauge')).toBe(true);
  });

  it('should record performance metrics', () => {
    const perfMetrics = {
      timestamp: new Date(),
      cpuUsage: {
        userCPU: 45.2,
        systemCPU: 15.8,
        totalUsage: 61.0,
        loadAverage: [1.2, 1.1, 1.0]
      },
      memoryUsage: {
        heapUsed: 125829120,
        heapTotal: 157286400,
        external: 1234567,
        rss: 178257920,
        buffers: 0,
        cached: 0,
        available: 8000000000,
        usagePercentage: 2.2
      },
      responseTime: {
        average: 245.6,
        median: 198.3,
        p95: 567.2,
        p99: 789.1,
        min: 45.2,
        max: 1234.5,
        samples: [100, 200, 300]
      },
      throughput: {
        requestsPerSecond: 125.4,
        operationsPerSecond: 125.4,
        tasksCompleted: 627,
        concurrentTasks: 5
      },
      errorRate: {
        totalErrors: 3,
        errorRate: 0.48,
        errorsByType: { 'validation': 2, 'network': 1 },
        criticalErrors: 0
      },
      customMetrics: {
        queueSize: 12,
        cacheHitRate: 94.5
      }
    };

    collector.recordPerformanceMetrics(perfMetrics);

    const allMetrics = collector.getAllMetrics();
    expect(allMetrics.size).toBeGreaterThan(10); // Should have recorded many metrics
    expect(allMetrics.has('cpu.total')).toBe(true);
    expect(allMetrics.has('memory.usage_percent')).toBe(true);
    expect(allMetrics.has('response_time.avg')).toBe(true);
  });

  it('should increment counters and set gauges', () => {
    collector.incrementCounter('requests.total', 1, { endpoint: '/api/test' });
    collector.incrementCounter('requests.total', 3, { endpoint: '/api/test' });
    collector.setGauge('connection.pool.size', 25, { pool: 'primary' });

    const metrics = collector.getAllMetrics();
    expect(metrics.has('requests.total')).toBe(true);
    expect(metrics.has('connection.pool.size')).toBe(true);
  });

  it('should query metrics with filters', () => {
    const oneMinuteAgo = new Date(Date.now() - 60000);

    collector.recordMetric('test.metric', 100, { env: 'prod' });
    collector.recordMetric('test.metric', 200, { env: 'dev' });
    collector.recordMetric('other.metric', 300, { env: 'prod' });

    // Query by name
    const testMetrics = collector.queryMetrics({ name: 'test.metric' });
    expect(testMetrics.length).toBe(2);

    // Query by tags
    const prodMetrics = collector.queryMetrics({ tags: { env: 'prod' } });
    expect(prodMetrics.length).toBe(2);

    // Query by time range - use current time after recording metrics
    const now = new Date();
    const recentMetrics = collector.queryMetrics({
      timeRange: { start: oneMinuteAgo, end: now }
    });
    expect(recentMetrics.length).toBe(3);
  });

  it('should export metrics in different formats', () => {
    collector.recordMetric('export.test', 42, { type: 'test' });

    const jsonExport = collector.exportMetrics({ format: 'json', includeLabels: true });
    expect(jsonExport).toContain('export.test');
    expect(JSON.parse(jsonExport)).toBeTruthy();

    const prometheusExport = collector.exportMetrics({ format: 'prometheus', includeLabels: true });
    expect(prometheusExport).toContain('export_test');
    expect(prometheusExport).toContain('# HELP');

    const csvExport = collector.exportMetrics({ format: 'csv', includeLabels: true });
    expect(csvExport).toContain('timestamp,name,value,unit,type');
    expect(csvExport).toContain('export.test');
  });

  it('should create snapshots', () => {
    collector.recordMetric('snapshot.test1', 10);
    collector.recordMetric('snapshot.test2', 20);

    const snapshot = collector.createSnapshot();
    expect(snapshot.summary.totalMetrics).toBe(2);
    expect(snapshot.summary.uniqueNames).toBe(2);
    expect(snapshot.metrics.length).toBe(2);
  });
});

describe('Alert Manager', () => {
  let alertManager: AlertManager;

  beforeEach(() => {
    alertManager = new AlertManager();
  });

  afterEach(() => {
    alertManager.stop();
  });

  it('should start and stop', () => {
    alertManager.start();
    expect(() => alertManager.stop()).not.toThrow();
  });

  it('should add and remove alert rules', () => {
    const rule = {
      id: 'test-rule',
      name: 'Test Rule',
      description: 'Test alert rule',
      metric: 'test.metric',
      condition: {
        operator: 'gt' as const,
        threshold: 100
      },
      severity: 'warning' as const,
      enabled: true,
      silenced: false,
      evaluationInterval: 60000,
      notifications: [],
      tags: {}
    };

    alertManager.addRule(rule);
    expect(() => alertManager.removeRule(rule.id)).not.toThrow();
  });

  it('should process performance alerts', () => {
    const perfAlert = {
      id: 'perf-alert-1',
      type: 'critical' as const,
      category: 'memory' as const,
      message: 'Critical memory usage: 95.2%',
      threshold: 90,
      currentValue: 95.2,
      timestamp: new Date(),
      recommendations: ['Free up memory', 'Restart if necessary']
    };

    alertManager.processPerformanceAlert(perfAlert);

    const activeAlerts = alertManager.getActiveAlerts();
    expect(activeAlerts.length).toBe(1);
    expect(activeAlerts[0].severity).toBe('critical');
  });

  it('should process metrics and evaluate rules', () => {
    // Add a rule that should trigger
    alertManager.addRule({
      id: 'cpu-high',
      name: 'High CPU',
      description: 'CPU usage too high',
      metric: 'cpu.usage',
      condition: {
        operator: 'gt',
        threshold: 80
      },
      severity: 'warning',
      enabled: true,
      silenced: false,
      evaluationInterval: 1000,
      notifications: [],
      tags: {}
    });

    alertManager.start();

    // Send metric that should trigger alert
    alertManager.processMetric({
      name: 'cpu.usage',
      value: 85,
      timestamp: new Date(),
      tags: {},
      unit: '%',
      type: 'gauge'
    });

    // Note: In a real test, we'd wait for evaluation or trigger it manually
    expect(alertManager.getActiveAlerts().length).toBeGreaterThanOrEqual(0);
  });

  it('should silence and unsilence alerts', () => {
    const perfAlert = {
      id: 'alert-to-silence',
      type: 'warning' as const,
      category: 'cpu' as const,
      message: 'High CPU usage',
      threshold: 70,
      currentValue: 75,
      timestamp: new Date(),
      recommendations: ['Monitor usage']
    };

    alertManager.processPerformanceAlert(perfAlert);
    const alerts = alertManager.getActiveAlerts();
    
    if (alerts.length > 0) {
      const alertId = alerts[0].id;
      alertManager.silenceAlert(alertId, 60000); // 1 minute
      expect(() => alertManager.unsilenceAlert(alertId)).not.toThrow();
    }
  });

  it('should provide alert summary', () => {
    // Add some test alerts
    alertManager.processPerformanceAlert({
      id: 'test-alert-1',
      type: 'warning',
      category: 'cpu',
      message: 'Test warning',
      threshold: 70,
      currentValue: 75,
      timestamp: new Date(),
      recommendations: []
    });

    alertManager.processPerformanceAlert({
      id: 'test-alert-2',
      type: 'critical',
      category: 'memory',
      message: 'Test critical',
      threshold: 90,
      currentValue: 95,
      timestamp: new Date(),
      recommendations: []
    });

    const summary = alertManager.getAlertSummary();
    expect(summary.total).toBeGreaterThanOrEqual(2);
    expect(summary.bySeverity.warning).toBeGreaterThanOrEqual(1);
    expect(summary.bySeverity.critical).toBeGreaterThanOrEqual(1);
  });
});

describe('Monitoring System Integration', () => {
  let monitoringSystem: MonitoringSystem;

  beforeEach(() => {
    monitoringSystem = new MonitoringSystem({
      performanceMonitor: {
        interval: 100
      },
      metricsCollector: {
        aggregationInterval: 100
      },
      integration: {
        autoStart: false
      }
    });
  });

  afterEach(async () => {
    await monitoringSystem.stop();
  });

  it('should start and stop the complete system', async () => {
    await monitoringSystem.start();
    expect(() => monitoringSystem.stop()).not.toThrow();
  });

  it('should track operations and errors', () => {
    const startTime = performance.now();
    monitoringSystem.trackOperation('test-op', startTime);
    monitoringSystem.trackError('test-error');
    
    expect(() => monitoringSystem.recordMetric('custom.metric', 42)).not.toThrow();
  });

  it('should provide health status', () => {
    const health = monitoringSystem.getHealthStatus();
    expect(health.overall).toMatch(/healthy|degraded|critical/);
    expect(health.components).toBeTruthy();
    expect(health.metrics.uptime).toBeGreaterThanOrEqual(0);
  });

  it('should provide dashboard data', () => {
    const dashboard = monitoringSystem.getDashboard();
    expect(dashboard.timestamp).toBeInstanceOf(Date);
    expect(dashboard.healthStatus).toBeTruthy();
    expect(dashboard.alertSummary).toBeTruthy();
    expect(dashboard.systemStats).toBeTruthy();
  });

  it('should export metrics', () => {
    monitoringSystem.recordMetric('export.test', 123);
    
    const jsonExport = monitoringSystem.exportMetrics('json');
    expect(jsonExport).toBeTruthy();
    
    const prometheusExport = monitoringSystem.exportMetrics('prometheus');
    expect(prometheusExport).toBeTruthy();
  });

  it('should handle cleanup', () => {
    monitoringSystem.recordMetric('cleanup.test', 456);
    expect(() => monitoringSystem.cleanup()).not.toThrow();
  });

  it('should emit integration events', (done) => {
    let eventCount = 0;
    const expectedEvents = ['metricsUpdated'];
    
    monitoringSystem.on('metricsUpdated', () => {
      eventCount++;
      if (eventCount >= 1) {
        done();
      }
    });

    monitoringSystem.start();
    
    // Force metrics collection
    setTimeout(() => {
      monitoringSystem.forceMetricsCollection();
    }, 50);
  });
});