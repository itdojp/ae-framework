/**
 * Intelligent Test Selection System for Phase 3.2
 * Provides smart test selection based on code changes and dependencies
 */

import { EventEmitter } from 'events';
import type { DependencyAnalysisResult } from '../analysis/dependency-analyzer.js';
import type { SequentialInferenceEngine } from '../engines/sequential-inference-engine.js';
import type { E2ETestCase } from './playwright-integration.js';
import type { VisualTestCase } from './visual-regression.js';

export interface TestSelectionRequest {
  id: string;
  changes: CodeChange[];
  testInventory: TestInventory;
  dependencyAnalysis: DependencyAnalysisResult;
  constraints: SelectionConstraints;
  strategy: SelectionStrategy;
  preferences: SelectionPreferences;
}

export interface SelectionPreferences {
  prioritizeRecentChanges: boolean;
  includeFlakyTests: boolean;
  parallelExecution: boolean;
  regressionFocus: boolean;
}

export interface CodeChange {
  id: string;
  type: 'addition' | 'modification' | 'deletion' | 'rename';
  filePath: string;
  componentId: string;
  impact: 'low' | 'medium' | 'high' | 'critical';
  changeType: 'logic' | 'interface' | 'data' | 'feature' | 'bug';
  linesChanged: number;
  additions: number;
  deletions: number;
  riskScore: number; // 0-1
  description: string;
}

export interface TestInventory {
  id: string;
  timestamp: Date;
  totalTests: number;
  testSuites: TestSuite[];
  coverage: {
    overall: number;
    byComponent: Record<string, number>;
    byTestType: Record<string, number>;
  };
  metrics: {
    avgExecutionTime: number;
    flakyTests: number;
    recentFailures: number;
  };
}

export interface TestSuite {
  id: string;
  name: string;
  type: 'unit' | 'integration' | 'e2e' | 'visual' | 'performance' | 'contract';
  tests: TestCase[];
}

export interface TestCase {
  id: string;
  name: string;
  type: 'unit' | 'integration' | 'e2e' | 'visual' | 'performance' | 'contract';
  filePath: string;
  componentCoverage: string[];
  priority: 'low' | 'medium' | 'high' | 'critical';
  executionTime: number;
  lastRun: Date;
  successRate: number;
  tags: string[];
}

export interface UnitTest {
  id: string;
  name: string;
  filePath: string;
  testFunction: string;
  coveredCode: string[];
  dependencies: string[];
  executionTime: number;
  stability: number; // 0-1, based on flakiness
  lastModified: Date;
  tags: string[];
}

export interface IntegrationTest {
  id: string;
  name: string;
  filePath: string;
  coveredComponents: string[];
  integrationPoints: string[];
  executionTime: number;
  stability: number;
  complexity: 'low' | 'medium' | 'high';
  dependencies: string[];
  tags: string[];
}

export interface PerformanceTest {
  id: string;
  name: string;
  filePath: string;
  measuredMetrics: string[];
  affectedComponents: string[];
  executionTime: number;
  sensitivity: number; // How sensitive to changes
  tags: string[];
}

export interface ContractTest {
  id: string;
  name: string;
  provider: string;
  consumer: string;
  contractFile: string;
  coveredAPIs: string[];
  executionTime: number;
  tags: string[];
}

export interface SelectionConstraints {
  maxExecutionTime: number; // Maximum total execution time
  maxTestCount: number; // Maximum number of tests
  requiredCoverage: number; // Minimum coverage percentage
  priorityLevels: ('critical' | 'high' | 'medium' | 'low')[];
  testTypes: ('unit' | 'integration' | 'e2e' | 'visual' | 'performance' | 'contract')[];
  excludeFlaky: boolean;
  parallelizationFactor: number; // How much parallel execution is available
}

export interface SelectionStrategy {
  mode: 'risk_based' | 'coverage_based' | 'dependency_based' | 'hybrid' | 'time_optimized';
  riskWeighting: RiskWeighting;
  coverageStrategy: CoverageStrategy;
  optimizationGoals: OptimizationGoal[];
}

export interface RiskWeighting {
  changeImpact: number; // 0-1
  componentCriticality: number; // 0-1
  historicalFailures: number; // 0-1
  dependencyComplexity: number; // 0-1
}

export interface CoverageStrategy {
  prioritizeUncovered: boolean;
  includeRegression: boolean;
  minimumCoverage: number;
  coverageType: 'line' | 'branch' | 'function' | 'statement';
}

export interface OptimizationGoal {
  type: 'minimize_time' | 'maximize_coverage' | 'maximize_confidence' | 'minimize_flakiness';
  weight: number; // 0-1
}

export interface TestSelectionResult {
  requestId: string;
  selectedTests: SelectedTestSuite;
  analysis: SelectionAnalysis;
  executionPlan: TestExecutionPlan;
  metrics: SelectionMetrics;
  recommendations: SelectionRecommendation[];
}

export interface SelectedTestSuite {
  unitTests: UnitTest[];
  integrationTests: IntegrationTest[];
  e2eTests: E2ETestCase[];
  visualTests: VisualTestCase[];
  performanceTests: PerformanceTest[];
  contractTests: ContractTest[];
  totalTests: number;
  estimatedExecutionTime: number;
  estimatedCoverage: number;
}

export interface SelectionAnalysis {
  changeImpactAnalysis: ChangeImpactAnalysis;
  riskAssessment: TestRiskAssessment;
  coverageGaps: CoverageGap[];
  dependencyImpact: DependencyImpact[];
  confidenceScore: number; // 0-1
}

export interface ChangeImpactAnalysis {
  directlyAffectedTests: string[];
  indirectlyAffectedTests: string[];
  riskDistribution: {
    critical: number;
    high: number;
    medium: number;
    low: number;
  };
  impactRadius: number; // How far the impact spreads
}

export interface TestRiskAssessment {
  overallRisk: 'low' | 'medium' | 'high' | 'critical';
  riskFactors: TestRiskFactor[];
  mitigationStrategies: string[];
  confidenceLevel: number;
}

export interface TestRiskFactor {
  id: string;
  type: 'coverage_gap' | 'flaky_test' | 'missing_dependency' | 'performance_risk';
  severity: 'low' | 'medium' | 'high' | 'critical';
  description: string;
  affectedTests: string[];
  likelihood: number; // 0-1
  impact: number; // 0-1
}

export interface CoverageGap {
  type: 'function' | 'branch' | 'line' | 'component';
  identifier: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  recommendedTests: string[];
}

export interface DependencyImpact {
  component: string;
  dependentComponents: string[];
  testCoverage: number;
  riskLevel: 'low' | 'medium' | 'high' | 'critical';
  recommendedTests: string[];
}

export interface TestExecutionPlan {
  phases: TestExecutionPhase[];
  parallelGroups: ParallelGroup[];
  totalEstimatedTime: number;
  resourceRequirements: ResourceRequirement[];
  optimizations: ExecutionOptimization[];
}

export interface TestExecutionPhase {
  id: string;
  name: string;
  tests: string[];
  estimatedTime: number;
  dependencies: string[];
  canParallelize: boolean;
  priority: number;
}

export interface ParallelGroup {
  id: string;
  tests: string[];
  estimatedTime: number;
  resourceWeight: number;
}

export interface ResourceRequirement {
  type: 'cpu' | 'memory' | 'network' | 'browser' | 'database';
  amount: number;
  unit: string;
  duration: number;
}

export interface ExecutionOptimization {
  type: 'test_ordering' | 'parallel_grouping' | 'resource_sharing' | 'early_termination';
  description: string;
  expectedBenefit: string;
  implementation: string;
}

export interface SelectionMetrics {
  selectionEfficiency: number; // Tests selected / Total available
  coverageEfficiency: number; // Coverage achieved / Time spent
  riskMitigation: number; // Risk reduced by selected tests
  timeOptimization: number; // Time saved vs. running all tests
  confidenceGain: number; // Confidence improvement
}

export interface SelectionRecommendation {
  id: string;
  type: 'strategy' | 'coverage' | 'performance' | 'maintenance';
  priority: 'high' | 'medium' | 'low';
  title: string;
  description: string;
  impact: string;
  effort: 'low' | 'medium' | 'high';
  implementation: string[];
}

export class IntelligentTestSelection extends EventEmitter {
  private inferenceEngine: SequentialInferenceEngine;
  private testExecutionHistory: Map<string, TestExecutionMetrics> = new Map();
  private flakinessTracker: Map<string, FlakinessMetrics> = new Map();
  private coverageDatabase: Map<string, CoverageData> = new Map();

  constructor(inferenceEngine: SequentialInferenceEngine) {
    super();
    this.inferenceEngine = inferenceEngine;
    this.setupEventHandlers();
  }

  /**
   * Select optimal tests based on code changes and constraints
   */
  async selectTests(request: TestSelectionRequest): Promise<TestSelectionResult> {
    this.emit('testSelectionStarted', request);

    try {
      // Use inference engine for complex analysis
      const analysisQuery = {
        id: `test-selection-${request.id}`,
        description: 'Analyze optimal test selection strategy',
        constraints: {
          maxDepth: 10,
          timeout: 60000
        },
        context: {
          changes: request.changes,
          constraints: request.constraints,
          strategy: request.strategy,
          dependencyAnalysis: request.dependencyAnalysis
        },
        priority: 'high' as const
      };

      const inferenceResult = await this.inferenceEngine.processComplexQuery(analysisQuery);

      // Perform change impact analysis
      const changeImpactAnalysis = await this.analyzeChangeImpact(
        request.changes,
        request.testInventory,
        request.dependencyAnalysis
      );

      // Calculate test risks and priorities
      const riskAssessment = this.assessTestRisks(request.changes, request.testInventory);

      // Select tests based on strategy
      const selectedTests = await this.executeSelectionStrategy(
        request,
        changeImpactAnalysis,
        riskAssessment
      );

      // Create execution plan
      const executionPlan = this.createOptimalExecutionPlan(selectedTests, request.constraints);

      // Calculate metrics
      const metrics = this.calculateSelectionMetrics(selectedTests, request);

      // Generate recommendations
      const recommendations = this.generateSelectionRecommendations(
        selectedTests,
        changeImpactAnalysis,
        riskAssessment,
        request.constraints
      );

      const result: TestSelectionResult = {
        requestId: request.id,
        selectedTests,
        analysis: {
          changeImpactAnalysis,
          riskAssessment,
          coverageGaps: this.identifyCoverageGaps(selectedTests, request.changes),
          dependencyImpact: this.analyzeDependencyImpact(request.dependencyAnalysis, selectedTests),
          confidenceScore: this.calculateConfidenceScore(selectedTests, riskAssessment)
        },
        executionPlan,
        metrics,
        recommendations
      };

      this.emit('testSelectionCompleted', { request, result });
      return result;

    } catch (error) {
      this.emit('testSelectionError', { request, error });
      throw error;
    }
  }

  /**
   * Update test execution metrics for future selections
   */
  updateTestMetrics(testId: string, metrics: TestExecutionMetrics): void {
    this.testExecutionHistory.set(testId, metrics);
    this.updateFlakinessMetrics(testId, metrics);
  }

  /**
   * Analyze test coverage for given code changes
   */
  async analyzeCoverage(
    changes: CodeChange[],
    availableTests: TestInventory
  ): Promise<CoverageAnalysis> {
    const coveredFiles = new Set<string>();
    const uncoveredFiles = new Set<string>();

    // Analyze unit test coverage
    for (const test of availableTests.unitTests) {
      test.coveredCode.forEach(file => coveredFiles.add(file));
    }

    // Check which changed files are covered
    for (const change of changes) {
      if (!coveredFiles.has(change.filePath)) {
        uncoveredFiles.add(change.filePath);
      }
    }

    const totalChangedFiles = changes.length;
    const coveredChangedFiles = totalChangedFiles - uncoveredFiles.size;
    const coveragePercentage = coveredChangedFiles / totalChangedFiles;

    return {
      totalFiles: totalChangedFiles,
      coveredFiles: coveredChangedFiles,
      uncoveredFiles: Array.from(uncoveredFiles),
      coveragePercentage,
      gaps: this.identifyDetailedCoverageGaps(changes, availableTests)
    };
  }

  /**
   * Predict test execution time based on historical data
   */
  predictExecutionTime(tests: SelectedTestSuite): ExecutionTimePredicton {
    let totalTime = 0;
    let confidence = 1.0;

    // Calculate based on historical execution times
    const allTests = [
      ...tests.unitTests,
      ...tests.integrationTests,
      ...tests.e2eTests,
      ...tests.visualTests,
      ...tests.performanceTests,
      ...tests.contractTests
    ];

    for (const test of allTests) {
      const historicalData = this.testExecutionHistory.get(test.id);
      if (historicalData) {
        totalTime += historicalData.averageExecutionTime;
        confidence *= historicalData.reliability;
      } else {
        // Estimate based on test type
        totalTime += this.estimateTestTime(test);
        confidence *= 0.7; // Lower confidence for estimates
      }
    }

    return {
      estimatedTime: totalTime,
      confidence,
      breakdown: this.createTimeBreakdown(allTests),
      optimizationPotential: this.calculateOptimizationPotential(allTests)
    };
  }

  // Private helper methods
  private setupEventHandlers(): void {
    this.on('testSelectionStarted', (request) => {
      console.log(`🧠 Intelligent test selection started: ${request.id}`);
    });

    this.on('testSelectionCompleted', ({ result }) => {
      console.log(`✅ Selected ${result.selectedTests.totalTests} tests (estimated: ${result.selectedTests.estimatedExecutionTime}ms)`);
    });

    this.on('testSelectionError', ({ request, error }) => {
      console.error(`❌ Test selection failed for ${request.id}:`, error.message);
    });
  }

  private async analyzeChangeImpact(
    changes: CodeChange[],
    availableTests: TestInventory,
    dependencyAnalysis: DependencyAnalysisResult
  ): Promise<ChangeImpactAnalysis> {
    const directlyAffectedTests = new Set<string>();
    const indirectlyAffectedTests = new Set<string>();

    // Get all tests from test suites
    const allTests = availableTests.testSuites.flatMap(suite => suite.tests);

    // Find directly affected tests
    for (const change of changes) {
      // Check all tests
      allTests.forEach(test => {
        if (test.componentCoverage.includes(change.componentId)) {
          directlyAffectedTests.add(test.id);
        }
      });
    }

    // Find indirectly affected tests through dependencies
    for (const change of changes) {
      const affectedNode = dependencyAnalysis.nodes.find(node => node.id === change.componentId);
      if (affectedNode) {
        // Find all dependent nodes
        const dependentNodes = this.findAllDependents(affectedNode.id, dependencyAnalysis);
        
        // Find tests covering dependent nodes
        dependentNodes.forEach(nodeId => {
          allTests.forEach(test => {
            if (test.componentCoverage.includes(nodeId)) {
              indirectlyAffectedTests.add(test.id);
            }
          });
        });
      }
    }

    // Calculate risk distribution
    const riskCounts = { critical: 0, high: 0, medium: 0, low: 0 };
    changes.forEach(change => {
      riskCounts[change.impact]++;
    });

    return {
      directlyAffectedTests: Array.from(directlyAffectedTests),
      indirectlyAffectedTests: Array.from(indirectlyAffectedTests),
      riskDistribution: riskCounts,
      impactRadius: this.calculateImpactRadius(changes, dependencyAnalysis)
    };
  }

  private assessTestRisks(changes: CodeChange[], availableTests: TestInventory): TestRiskAssessment {
    const riskFactors: TestRiskFactor[] = [];

    // Check for flaky tests
    const flakyTests = this.identifyFlakyTests(availableTests);
    if (flakyTests.length > 0) {
      riskFactors.push({
        id: 'flaky-tests',
        type: 'flaky_test',
        severity: 'medium',
        description: `${flakyTests.length} flaky tests detected`,
        affectedTests: flakyTests,
        likelihood: 0.8,
        impact: 0.6
      });
    }

    // Check for coverage gaps
    const coverageGaps = this.findCoverageGaps(changes, availableTests);
    if (coverageGaps.length > 0) {
      riskFactors.push({
        id: 'coverage-gaps',
        type: 'coverage_gap',
        severity: 'high',
        description: `${coverageGaps.length} coverage gaps identified`,
        affectedTests: [],
        likelihood: 1.0,
        impact: 0.8
      });
    }

    const overallRisk = this.calculateOverallRisk(riskFactors);
    const confidenceLevel = this.calculateConfidenceLevel(riskFactors, availableTests);

    return {
      overallRisk,
      riskFactors,
      mitigationStrategies: this.generateMitigationStrategies(riskFactors),
      confidenceLevel
    };
  }

  private async executeSelectionStrategy(
    request: TestSelectionRequest,
    changeImpact: ChangeImpactAnalysis,
    riskAssessment: TestRiskAssessment
  ): Promise<SelectedTestSuite> {
    switch (request.strategy.mode) {
      case 'risk_based':
        return this.selectTestsByRisk(request, changeImpact, riskAssessment);
      case 'coverage_based':
        return this.selectTestsByCoverage(request, changeImpact);
      case 'dependency_based':
        return this.selectTestsByDependency(request, changeImpact);
      case 'time_optimized':
        return this.selectTestsByTime(request, changeImpact);
      case 'hybrid':
      default:
        return this.selectTestsHybrid(request, changeImpact, riskAssessment);
    }
  }

  private selectTestsHybrid(
    request: TestSelectionRequest,
    changeImpact: ChangeImpactAnalysis,
    riskAssessment: TestRiskAssessment
  ): SelectedTestSuite {
    const selected: SelectedTestSuite = {
      unitTests: [],
      integrationTests: [],
      e2eTests: [],
      visualTests: [],
      performanceTests: [],
      contractTests: [],
      totalTests: 0,
      estimatedExecutionTime: 0,
      estimatedCoverage: 0
    };

    // Start with directly affected tests (highest priority)
    const directlyAffectedTestIds = new Set(changeImpact.directlyAffectedTests);

    // Add critical unit tests
    selected.unitTests = request.availableTests.unitTests.filter(test => 
      directlyAffectedTestIds.has(test.id) || this.isHighPriorityTest(test, request.changes)
    ).slice(0, 50); // Limit to prevent excessive execution time

    // Add essential integration tests
    selected.integrationTests = request.availableTests.integrationTests.filter(test =>
      directlyAffectedTestIds.has(test.id) || this.coversChangedIntegrationPoints(test, request.changes)
    ).slice(0, 20);

    // Add critical E2E tests based on user impact
    selected.e2eTests = request.availableTests.e2eTests.filter(test =>
      test.priority === 'critical' || this.affectsUserJourney(test, request.changes)
    ).slice(0, 10);

    // Add visual tests for UI changes
    if (this.hasUIChanges(request.changes)) {
      selected.visualTests = request.availableTests.visualTests.filter(test =>
        test.priority === 'critical' || this.affectsVisualComponents(test, request.changes)
      ).slice(0, 15);
    }

    // Add performance tests if performance-critical code changed
    if (this.hasPerformanceCriticalChanges(request.changes)) {
      selected.performanceTests = request.availableTests.performanceTests.filter(test =>
        this.coversPerformanceCriticalComponents(test, request.changes)
      ).slice(0, 5);
    }

    // Calculate totals
    selected.totalTests = selected.unitTests.length + selected.integrationTests.length + 
                         selected.e2eTests.length + selected.visualTests.length +
                         selected.performanceTests.length + selected.contractTests.length;

    selected.estimatedExecutionTime = this.calculateTotalExecutionTime(selected);
    selected.estimatedCoverage = this.calculateEstimatedCoverage(selected, request.changes);

    return selected;
  }

  private selectTestsByRisk(
    request: TestSelectionRequest,
    changeImpact: ChangeImpactAnalysis,
    riskAssessment: TestRiskAssessment
  ): SelectedTestSuite {
    // Implementation for risk-based selection
    return this.selectTestsHybrid(request, changeImpact, riskAssessment);
  }

  private selectTestsByCoverage(
    request: TestSelectionRequest,
    changeImpact: ChangeImpactAnalysis
  ): SelectedTestSuite {
    // Implementation for coverage-based selection
    return this.selectTestsHybrid(request, changeImpact, {} as TestRiskAssessment);
  }

  private selectTestsByDependency(
    request: TestSelectionRequest,
    changeImpact: ChangeImpactAnalysis
  ): SelectedTestSuite {
    // Implementation for dependency-based selection
    return this.selectTestsHybrid(request, changeImpact, {} as TestRiskAssessment);
  }

  private selectTestsByTime(
    request: TestSelectionRequest,
    changeImpact: ChangeImpactAnalysis
  ): SelectedTestSuite {
    // Implementation for time-optimized selection
    return this.selectTestsHybrid(request, changeImpact, {} as TestRiskAssessment);
  }

  private createOptimalExecutionPlan(
    selectedTests: SelectedTestSuite,
    constraints: SelectionConstraints
  ): TestExecutionPlan {
    const phases: TestExecutionPhase[] = [];
    const parallelGroups: ParallelGroup[] = [];

    // Phase 1: Fast unit tests
    if (selectedTests.unitTests.length > 0) {
      phases.push({
        id: 'unit-tests-phase',
        name: 'Unit Tests',
        tests: selectedTests.unitTests.map(t => t.id),
        estimatedTime: selectedTests.unitTests.reduce((sum, t) => sum + t.executionTime, 0),
        dependencies: [],
        canParallelize: true,
        priority: 1
      });
    }

    // Phase 2: Integration tests
    if (selectedTests.integrationTests.length > 0) {
      phases.push({
        id: 'integration-tests-phase',
        name: 'Integration Tests',
        tests: selectedTests.integrationTests.map(t => t.id),
        estimatedTime: selectedTests.integrationTests.reduce((sum, t) => sum + t.executionTime, 0),
        dependencies: ['unit-tests-phase'],
        canParallelize: true,
        priority: 2
      });
    }

    // Phase 3: E2E and Visual tests (can run in parallel)
    if (selectedTests.e2eTests.length > 0 || selectedTests.visualTests.length > 0) {
      phases.push({
        id: 'e2e-visual-phase',
        name: 'E2E and Visual Tests',
        tests: [
          ...selectedTests.e2eTests.map(t => t.id),
          ...selectedTests.visualTests.map(t => t.id)
        ],
        estimatedTime: Math.max(
          selectedTests.e2eTests.reduce((sum, t) => sum + (t.steps?.length || 10) * 1000, 0),
          selectedTests.visualTests.reduce((sum, t) => sum + 5000, 0) // Estimate 5s per visual test
        ),
        dependencies: ['integration-tests-phase'],
        canParallelize: true,
        priority: 3
      });
    }

    return {
      phases,
      parallelGroups,
      totalEstimatedTime: phases.reduce((sum, phase) => sum + phase.estimatedTime, 0),
      resourceRequirements: this.calculateResourceRequirements(selectedTests),
      optimizations: this.identifyExecutionOptimizations(phases, constraints)
    };
  }

  // Additional helper methods
  private findAllDependents(nodeId: string, analysis: DependencyAnalysisResult): string[] {
    const dependents = new Set<string>();
    
    function traverse(currentId: string) {
      const node = analysis.nodes.find(n => n.id === currentId);
      if (node) {
        node.dependents.forEach(depId => {
          if (!dependents.has(depId)) {
            dependents.add(depId);
            traverse(depId);
          }
        });
      }
    }
    
    traverse(nodeId);
    return Array.from(dependents);
  }

  private calculateImpactRadius(changes: CodeChange[], analysis: DependencyAnalysisResult): number {
    let maxRadius = 0;
    
    for (const change of changes) {
      const node = analysis.nodes.find(n => n.path === change.path);
      if (node) {
        const dependents = this.findAllDependents(node.id, analysis);
        maxRadius = Math.max(maxRadius, dependents.length);
      }
    }
    
    return maxRadius;
  }

  private identifyFlakyTests(availableTests: TestInventory): string[] {
    const flakyTests: string[] = [];
    
    // Check flakiness metrics
    for (const [testId, metrics] of this.flakinessTracker) {
      if (metrics.flakinessScore > 0.2) { // 20% flakiness threshold
        flakyTests.push(testId);
      }
    }
    
    return flakyTests;
  }

  private findCoverageGaps(changes: CodeChange[], availableTests: TestInventory): string[] {
    const gaps: string[] = [];
    const coveredPaths = new Set<string>();
    
    // Collect all covered paths
    availableTests.unitTests.forEach(test => {
      test.coveredCode.forEach(path => coveredPaths.add(path));
    });
    
    // Find uncovered changed files
    changes.forEach(change => {
      if (!coveredPaths.has(change.filePath)) {
        gaps.push(change.filePath);
      }
    });
    
    return gaps;
  }

  private calculateOverallRisk(riskFactors: TestRiskFactor[]): 'low' | 'medium' | 'high' | 'critical' {
    if (riskFactors.length === 0) return 'low';
    
    const avgRisk = riskFactors.reduce((sum, rf) => sum + rf.likelihood * rf.impact, 0) / riskFactors.length;
    
    if (avgRisk > 0.7) return 'critical';
    if (avgRisk > 0.5) return 'high';
    if (avgRisk > 0.3) return 'medium';
    return 'low';
  }

  private calculateConfidenceLevel(riskFactors: TestRiskFactor[], availableTests: TestInventory): number {
    const baseConfidence = 0.8;
    const riskPenalty = riskFactors.reduce((sum, rf) => sum + rf.impact * 0.1, 0);
    const testCoverageBonus = Math.min(availableTests.unitTests.length / 100, 0.2);
    
    return Math.max(0, Math.min(1, baseConfidence - riskPenalty + testCoverageBonus));
  }

  private generateMitigationStrategies(riskFactors: TestRiskFactor[]): string[] {
    const strategies: string[] = [];
    
    riskFactors.forEach(factor => {
      switch (factor.type) {
        case 'flaky_test':
          strategies.push('Stabilize flaky tests before relying on them');
          break;
        case 'coverage_gap':
          strategies.push('Add tests for uncovered critical code paths');
          break;
        case 'missing_dependency':
          strategies.push('Ensure all dependencies are properly tested');
          break;
        case 'performance_risk':
          strategies.push('Include performance regression tests');
          break;
      }
    });
    
    return [...new Set(strategies)]; // Remove duplicates
  }

  // Test classification helper methods
  private isHighPriorityTest(test: TestCase, changes: CodeChange[]): boolean {
    return changes.some(change => 
      change.impact === 'critical' && test.componentCoverage.includes(change.componentId)
    );
  }

  private coversChangedIntegrationPoints(test: TestCase, changes: CodeChange[]): boolean {
    return changes.some(change => 
      test.componentCoverage.includes(change.componentId)
    );
  }

  private affectsUserJourney(test: E2ETestCase, changes: CodeChange[]): boolean {
    // Check if changes affect critical user journey components
    return changes.some(change => change.impact === 'critical' || change.impact === 'high');
  }

  private hasUIChanges(changes: CodeChange[]): boolean {
    return changes.some(change => 
      change.filePath.includes('.css') || 
      change.filePath.includes('.scss') ||
      change.filePath.includes('.vue') ||
      change.filePath.includes('.jsx') ||
      change.filePath.includes('.tsx') ||
      change.filePath.includes('component')
    );
  }

  private affectsVisualComponents(test: VisualTestCase, changes: CodeChange[]): boolean {
    return changes.some(change => 
      test.componentCoverage.includes(change.componentId)
    );
  }

  private hasPerformanceCriticalChanges(changes: CodeChange[]): boolean {
    return changes.some(change => 
      change.riskScore > 0.7 || change.impact === 'critical'
    );
  }

  private coversPerformanceCriticalComponents(test: TestCase, changes: CodeChange[]): boolean {
    return changes.some(change => 
      test.componentCoverage.includes(change.componentId)
    );
  }

  private calculateTotalExecutionTime(selected: SelectedTestSuite): number {
    return selected.unitTests.reduce((sum, t) => sum + t.executionTime, 0) +
           selected.integrationTests.reduce((sum, t) => sum + t.executionTime, 0) +
           selected.e2eTests.reduce((sum, t) => sum + (t.steps?.length || 10) * 1000, 0) +
           selected.visualTests.reduce((sum, t) => sum + 5000, 0) +
           selected.performanceTests.reduce((sum, t) => sum + t.executionTime, 0) +
           selected.contractTests.reduce((sum, t) => sum + t.executionTime, 0);
  }

  private calculateEstimatedCoverage(selected: SelectedTestSuite, changes: CodeChange[]): number {
    const changedFiles = new Set(changes.map(c => c.path));
    const coveredFiles = new Set<string>();
    
    selected.unitTests.forEach(test => {
      test.coveredCode.forEach(file => coveredFiles.add(file));
    });
    
    const coveredChangedFiles = Array.from(changedFiles).filter(file => coveredFiles.has(file));
    return coveredChangedFiles.length / changedFiles.size;
  }

  private calculateResourceRequirements(selected: SelectedTestSuite): ResourceRequirement[] {
    return [
      {
        type: 'cpu',
        amount: selected.totalTests * 0.1,
        unit: 'cores',
        duration: selected.estimatedExecutionTime
      },
      {
        type: 'memory',
        amount: selected.totalTests * 50,
        unit: 'MB',
        duration: selected.estimatedExecutionTime
      }
    ];
  }

  private identifyExecutionOptimizations(
    phases: TestExecutionPhase[],
    constraints: SelectionConstraints
  ): ExecutionOptimization[] {
    return [
      {
        type: 'parallel_grouping',
        description: 'Group tests for parallel execution',
        expectedBenefit: `Reduce execution time by ${constraints.parallelizationFactor}x`,
        implementation: 'Use test runner parallel execution features'
      }
    ];
  }

  private identifyCoverageGaps(selected: SelectedTestSuite, changes: CodeChange[]): CoverageGap[] {
    // Implementation for identifying coverage gaps
    return [];
  }

  private analyzeDependencyImpact(
    analysis: DependencyAnalysisResult,
    selected: SelectedTestSuite
  ): DependencyImpact[] {
    // Implementation for dependency impact analysis
    return [];
  }

  private calculateConfidenceScore(
    selected: SelectedTestSuite,
    riskAssessment: TestRiskAssessment
  ): number {
    return Math.max(0, 1 - (riskAssessment.riskFactors.length * 0.1));
  }

  private calculateSelectionMetrics(
    selected: SelectedTestSuite,
    request: TestSelectionRequest
  ): SelectionMetrics {
    const totalAvailable = Object.values(request.availableTests).reduce((sum, tests) => sum + tests.length, 0);
    
    return {
      selectionEfficiency: selected.totalTests / totalAvailable,
      coverageEfficiency: selected.estimatedCoverage / (selected.estimatedExecutionTime / 1000),
      riskMitigation: 0.8, // Estimated
      timeOptimization: 1 - (selected.estimatedExecutionTime / 3600000), // vs 1 hour full suite
      confidenceGain: 0.75 // Estimated confidence improvement
    };
  }

  private generateSelectionRecommendations(
    selected: SelectedTestSuite,
    changeImpact: ChangeImpactAnalysis,
    riskAssessment: TestRiskAssessment,
    constraints: SelectionConstraints
  ): SelectionRecommendation[] {
    return [
      {
        id: 'optimize-selection',
        type: 'strategy',
        priority: 'medium',
        title: 'Optimize Test Selection Strategy',
        description: 'Current selection could be optimized for better coverage/time ratio',
        impact: 'Improved testing efficiency',
        effort: 'low',
        implementation: [
          'Analyze test execution patterns',
          'Adjust selection weights',
          'Consider hybrid strategies'
        ]
      }
    ];
  }

  private updateFlakinessMetrics(testId: string, metrics: TestExecutionMetrics): void {
    const current = this.flakinessTracker.get(testId) || {
      executions: 0,
      failures: 0,
      flakyRuns: 0,
      flakinessScore: 0
    };

    current.executions++;
    if (!metrics.success) current.failures++;
    if (metrics.flaky) current.flakyRuns++;
    
    current.flakinessScore = current.flakyRuns / current.executions;
    this.flakinessTracker.set(testId, current);
  }

  private identifyDetailedCoverageGaps(
    changes: CodeChange[],
    availableTests: TestInventory
  ): CoverageGap[] {
    // Implementation for detailed coverage gap analysis
    return [];
  }

  private estimateTestTime(test: any): number {
    // Estimate test execution time based on test type
    if ('steps' in test) return test.steps.length * 1000; // E2E test
    if ('complexity' in test) return test.complexity === 'high' ? 5000 : 2000; // Integration test
    return 1000; // Default unit test time
  }

  private createTimeBreakdown(tests: any[]): Record<string, number> {
    return {
      unit: tests.filter(t => 'coveredCode' in t).length * 1000,
      integration: tests.filter(t => 'integrationPoints' in t).length * 2000,
      e2e: tests.filter(t => 'steps' in t).length * 10000,
      visual: tests.filter(t => 'baseline' in t).length * 5000
    };
  }

  private calculateOptimizationPotential(tests: any[]): number {
    // Calculate potential time savings through optimization
    return tests.length * 0.1; // 10% optimization potential
  }
}

// Supporting interfaces for metrics and analysis
interface TestExecutionMetrics {
  success: boolean;
  executionTime: number;
  averageExecutionTime: number;
  reliability: number;
  flaky: boolean;
}

interface FlakinessMetrics {
  executions: number;
  failures: number;
  flakyRuns: number;
  flakinessScore: number;
}

interface CoverageData {
  lines: number;
  branches: number;
  functions: number;
  statements: number;
}

interface CoverageAnalysis {
  totalFiles: number;
  coveredFiles: number;
  uncoveredFiles: string[];
  coveragePercentage: number;
  gaps: CoverageGap[];
}

interface ExecutionTimePredicton {
  estimatedTime: number;
  confidence: number;
  breakdown: Record<string, number>;
  optimizationPotential: number;
}