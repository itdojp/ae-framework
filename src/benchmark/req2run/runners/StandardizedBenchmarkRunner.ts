/**
 * Standardized Req2Run Benchmark Runner
 * Uses the new AE Framework standardized pipeline for consistent benchmark execution
 * This replaces the original BenchmarkRunner with standardized interfaces
 */

import type { 
  RequirementSpec, 
  BenchmarkResult, 
  BenchmarkMetrics, 
  AgenticProgrammingMetrics,
  BenchmarkConfig, 
  PhaseExecution,
  ExecutionDetails,
  GeneratedArtifacts,
  BenchmarkError 
} from '../types/index.js';
import { AEFrameworkPhase } from '../types/index.js';
import os from 'node:os';
import fs from 'fs/promises';
import yaml from 'yaml';

// Import standardized pipeline and adapters
import { AEFrameworkPipeline } from '../../../agents/pipeline/ae-framework-pipeline.js';
import type { PipelineConfig, PipelineResult } from '../../../agents/pipeline/ae-framework-pipeline.js';
import { IntentAgentAdapter } from '../../../agents/adapters/intent-agent-adapter.js';
import { 
  RequirementsAgentAdapter, 
  UserStoriesAgentAdapter, 
  ValidationAgentAdapter, 
  DomainModelingAgentAdapter 
} from '../../../agents/adapters/task-adapters.js';
import { UIUXAgentAdapter } from '../../../agents/adapters/ui-ux-agent-adapter.js';
import type { 
  IntentInput, 
  RequirementSource, 
  ProjectContext,
  PhaseResult,
  UIUXOutput,
  UIComponent
} from '../../../agents/interfaces/standard-interfaces.js';
import { BenchmarkCategory, DifficultyLevel, OutputType } from '../types/index.js';
import {
  generateAnalytics,
  generateCSVReport,
  generateEnhancedMarkdownReport,
  type AnalyticsData,
  type EnhancedReportData,
} from './standardized-benchmark-report.js';

// Minimal generated file descriptor used within this runner (file-local type)
type GeneratedFile = { path: string; content: string; type: 'typescript' | 'markdown' | 'config' | string; size: number };
type FunctionalReq = { id?: string; description?: string; priority?: string; acceptance_criteria?: string[] };
type NonFunctionalRequirements = Record<string, Array<string | { description?: string }>>;
type PhaseSummary = { phase: string; success: boolean; duration: number; errors: number };

// Local, minimal view of the req2run problem YAML we normalize from
type MinimalSpec = {
  id?: string;
  title?: string;
  notes?: string;
  category?: string;
  difficulty?: string;
  estimated_time_minutes?: number;
  metadata?: { author?: string; created_date?: string; version?: string };
  requirements?: {
    functional?: FunctionalReq[];
    non_functional?: NonFunctionalRequirements | undefined;
  };
  constraints?: {
    allowed_packages?: string[];
    disallowed_packages?: string[];
    platform?: string[];
  };
  testCriteria?: unknown[];
  expectedOutput?: { type?: string; value?: unknown };
};

/**
 * Standardized Benchmark Runner
 * Leverages the AE Framework standardized pipeline for consistent, maintainable benchmark execution
 */
export class StandardizedBenchmarkRunner {
  private config: BenchmarkConfig;
  private pipeline!: AEFrameworkPipeline;

  constructor(config: BenchmarkConfig) {
    this.config = config;
    this.initializePipeline();
  }

  /**
   * Run a single benchmark problem using standardized pipeline
   */
  async runBenchmark(problemId: string): Promise<BenchmarkResult> {
    const startTime = new Date();

    try {
      // Load problem specification
      const spec = await this.loadProblemSpec(problemId);
      
      // Convert to standardized input format
      const pipelineInput = this.convertToStandardInput(spec);
      
      // Execute standardized AE Framework pipeline
      const pipelineResult = await this.pipeline.executePipeline(pipelineInput);
      
      // Convert pipeline result to benchmark result
      const benchmarkResult = await this.convertToBenchmarkResult(
        pipelineResult, 
        problemId, 
        spec, 
        startTime
      );

      return benchmarkResult;

    } catch (error) {
      return this.buildErrorResult(error, problemId, startTime);
    }
  }

  /**
   * Run multiple benchmark problems with standardized pipeline
   */
  async runBenchmarks(problemIds: string[]): Promise<BenchmarkResult[]> {
    const results: BenchmarkResult[] = [];

    if (this.config.execution.parallel) {
      // Parallel execution with concurrency limit
      const chunks = this.chunkArray(problemIds, this.config.execution.maxConcurrency);
      
      for (const chunk of chunks) {
        const chunkResults = await Promise.all(
          chunk.map(id => this.runBenchmark(id))
        );
        results.push(...chunkResults);
      }
    } else {
      // Sequential execution
      for (const problemId of problemIds) {
        const result = await this.runBenchmark(problemId);
        results.push(result);
      }
    }

    // Generate comprehensive report
    await this.generateComprehensiveReport(results);

    return results;
  }

  /**
   * Get pipeline capabilities and health status
   */
  getPipelineStatus(): {
    capabilities: Record<string, unknown>;
    validation: { valid: boolean; missing: string[]; errors: string[] };
    health: 'healthy' | 'degraded' | 'failed';
  } {
    const capabilities = this.pipeline.getPipelineCapabilities();
    const validation = this.pipeline.validatePipeline();
    
    let health: 'healthy' | 'degraded' | 'failed' = 'healthy';
    if (validation.missing.length > 0) {
      health = validation.missing.includes('ui-ux-generation') ? 'degraded' : 'failed';
    }

    return { capabilities, validation, health };
  }

  /**
   * Initialize standardized AE Framework pipeline
   */
  private initializePipeline(): void {
    const pipelineConfig: PipelineConfig = {
      projectId: `benchmark-${Date.now()}`,
      domain: 'benchmark-execution',
      validateInputs: true,
      retryFailures: this.config.execution.retryOnFailure || true,
      maxRetries: 2,
      timeoutMs: this.config.execution.timeout || 300000
    };

    this.pipeline = new AEFrameworkPipeline(pipelineConfig);

    // Register all standardized adapters
    this.pipeline.registerAgent('intent', new IntentAgentAdapter());
    this.pipeline.registerAgent('requirements', new RequirementsAgentAdapter());
    this.pipeline.registerAgent('user-stories', new UserStoriesAgentAdapter());
    this.pipeline.registerAgent('validation', new ValidationAgentAdapter());
    this.pipeline.registerAgent('domain-modeling', new DomainModelingAgentAdapter());
    this.pipeline.registerAgent('ui-ux-generation', new UIUXAgentAdapter());

    // Validate pipeline setup
    const validation = this.pipeline.validatePipeline();
    if (!validation.valid) {
      console.warn('‚ö†Ô∏è  Pipeline validation warnings:', validation.errors);
    }
  }

  /**
   * Load and parse problem specification from req2run-benchmark
   */
  private async loadProblemSpec(problemId: string): Promise<RequirementSpec> {
    try {
      const repoDir = process.env['REQ2RUN_BENCHMARK_REPO'] || '/tmp/req2run-benchmark';
      
      // Check repository availability
      try {
        await fs.access(repoDir);
      } catch {
        throw new Error(`Req2Run benchmark repository not found at ${repoDir}. Please clone and set REQ2RUN_BENCHMARK_REPO environment variable.`);
      }

      // Find problem file across difficulty levels
      const difficulties = ['basic', 'intermediate', 'advanced', 'expert'];
      let problemFile: string | null = null;
      
      for (const difficulty of difficulties) {
        const filePath = `${repoDir}/problems/${difficulty}/${problemId}.yaml`;
        try {
          await fs.access(filePath);
          problemFile = filePath;
          break;
        } catch {
          // Continue searching
        }
      }

      if (!problemFile) {
        throw new Error(`Problem specification not found for ${problemId}. Available problems can be found in the req2run-benchmark repository.`);
      }

      // Parse YAML specification
      const content = await fs.readFile(problemFile, 'utf-8');
      const spec = yaml.parse(content);

      // Convert to standardized RequirementSpec format
      return this.normalizeSpecification(spec, problemId);

    } catch (error) {
      throw new Error(`Failed to load problem spec for ${problemId}: ${error instanceof Error ? error.message : error}`);
    }
  }

  /**
   * Normalize req2run specification to AE Framework format
   */
  private normalizeSpecification(spec: unknown, problemId: string): RequirementSpec {
    const s = spec as MinimalSpec;
    const cat = (s.category && Object.values(BenchmarkCategory).includes(s.category as any))
      ? (s.category as BenchmarkCategory)
      : BenchmarkCategory.WEB_API;
    const diff = (s.difficulty && Object.values(DifficultyLevel).includes(s.difficulty as any))
      ? (s.difficulty as DifficultyLevel)
      : DifficultyLevel.INTERMEDIATE;
    return {
      id: String(s.id || problemId),
      title: String(s.title || `Benchmark Problem ${problemId}`),
      description: this.buildDescription(s),
      category: cat,
      difficulty: diff,
      requirements: this.extractRequirements(s),
      constraints: this.extractConstraints(s),
      testCriteria: [],
      expectedOutput: { type: OutputType.APPLICATION, format: 'executable', schema: null, examples: [] },
      metadata: {
        created_by: s.metadata?.author || 'req2run-benchmark',
        created_at: s.metadata?.created_date || new Date().toISOString(),
        version: s.metadata?.version || '1.0.0',
        category: cat,
        difficulty: diff,
        estimated_time: s.estimated_time_minutes || 30,
        benchmark_source: 'req2run-benchmark',
        problem_id: problemId
      }
    };
  }

  /**
   * Convert req2run spec to standardized pipeline input
   */
  private convertToStandardInput(spec: RequirementSpec): IntentInput {
    const sources: RequirementSource[] = [
      {
        type: 'specification',
        content: this.buildSpecificationContent(spec),
        metadata: {
          problemId: spec.id,
          category: spec.metadata.category,
          difficulty: spec.metadata.difficulty,
          source: 'req2run-benchmark'
        }
      }
    ];

    // Add constraints as additional context
    if (spec.constraints) {
      sources.push({
        type: 'document',
        content: `Constraints:\n${JSON.stringify(spec.constraints, null, 2)}`,
        metadata: {
          type: 'constraints',
          source: 'req2run-benchmark'
        }
      });
    }

    const context: any = {
      domain: spec.metadata.category || 'general',
      organization: 'Req2Run Benchmark',
      existingSystem: false,
      constraints: Object.entries(spec.constraints || {}).map(([key, value]) => ({
        type: ((): 'technical' | 'business' | 'regulatory' | 'resource' => {
          const m: Record<string, 'technical' | 'business' | 'regulatory' | 'resource'> = {
            technical: 'technical',
            business: 'business',
            regulatory: 'regulatory',
            resource: 'resource',
          };
          return m[key] ?? 'technical';
        })(),
        description: Array.isArray(value) ? value.join(', ') : JSON.stringify(value),
        impact: 'high',
        source: 'req2run-benchmark'
      }))
    };

    return { sources, context: context as ProjectContext };
  }

  /**
   * Convert pipeline result to benchmark result format
   */
  private async convertToBenchmarkResult(
    pipelineResult: PipelineResult, 
    problemId: string, 
    spec: RequirementSpec, 
    startTime: Date
  ): Promise<BenchmarkResult> {
    const endTime = new Date();

    // Convert pipeline phases to benchmark phase executions
    const phaseExecutions: PhaseExecution[] = pipelineResult.phases.map(phase => {
      const errMsgs = phase.errors?.map(e => e.message) || [];
      return {
        phase: this.mapStandardPhaseToLegacy(phase.phase),
        startTime: phase.metadata.startTime,
        endTime: phase.metadata.endTime,
        duration: phase.metadata.duration,
        input: this.extractPhaseInput(phase),
        output: phase.data,
        success: phase.success,
        ...(errMsgs.length > 0 ? { errors: errMsgs } : {}),
      };
    });

    // Extract generated artifacts from final phase
    const generatedArtifacts = await this.extractGeneratedArtifacts(pipelineResult);

    // Calculate comprehensive metrics
    const metrics = await this.calculateBenchmarkMetrics(pipelineResult, spec);

    // Build execution details
    const executionDetails: ExecutionDetails = {
      startTime,
      endTime,
      totalDuration: endTime.getTime() - startTime.getTime(),
      phaseExecutions,
      environment: await this.getExecutionEnvironment(),
      logs: pipelineResult.metadata.dataFlowTrace.map(trace => ({
        timestamp: new Date().toISOString(),
        level: 'info' as const,
        message: `Phase ${trace.phase}: ${trace.inputSize} ‚Üí ${trace.outputSize} bytes`,
        phase: trace.phase
      }))
    };

    return {
      problemId,
      timestamp: endTime,
      success: pipelineResult.success,
      metrics,
      executionDetails,
      generatedArtifacts,
      ...(pipelineResult.errors.length > 0 ? {
        errors: pipelineResult.errors.map(e => ({
          phase: this.mapStandardPhaseToLegacy(e.phase),
          type: 'runtime',
          message: e.message,
          ...(e.stack ? { stack: e.stack } : {}),
          timestamp: new Date()
        }))
      } : {})
    };
  }

  /**
   * Calculate comprehensive benchmark metrics from pipeline results
   */
  private async calculateBenchmarkMetrics(
    pipelineResult: PipelineResult, 
    spec: RequirementSpec
  ): Promise<BenchmarkMetrics> {
    const baseScore = pipelineResult.success ? 60 : 0;
    let functionalCoverage = 0;
    let codeQualityScore = 0;

    // Analyze functional coverage
    const finalPhase = pipelineResult.phases[pipelineResult.phases.length - 1];
    if (finalPhase && finalPhase.success) {
      functionalCoverage = this.assessFunctionalCoverage(finalPhase.data, spec);
      codeQualityScore = this.assessCodeQuality(finalPhase.data);
    }

    // Calculate performance metrics
    const performanceScore = this.calculatePerformanceScore(pipelineResult);

    const turnCount = pipelineResult.metadata.dataFlowTrace.length;
    const avgLen =
      turnCount > 0
        ? Math.round(
            pipelineResult.metadata.dataFlowTrace.reduce((sum, t) => sum + t.outputSize, 0) / turnCount
          )
        : 0;
    const agentic: AgenticProgrammingMetrics = {
      schemaVersion: '2.0.0',
      tokens: { prompt: null, completion: null, tool: null, total: null },
      costUsd: null,
      memoryHitRatio: null,
      turns: { count: turnCount, avgLen },
      latencyMs: pipelineResult.totalDuration,
    };

    return {
      overallScore: Math.min(100, baseScore + functionalCoverage * 0.3 + codeQualityScore * 0.1),
      functionalCoverage,
      testPassRate: pipelineResult.success ? 85 : 0, // Placeholder - would need actual test execution
      performance: {
        responseTime: pipelineResult.totalDuration,
        throughput: this.calculateThroughput(pipelineResult),
        memoryUsage: Math.round(process.memoryUsage().heapUsed / (1024 * 1024)),
        cpuUsage: 0, // Would need actual CPU monitoring
        diskUsage: 0  // Would need actual disk monitoring
      },
      codeQuality: {
        codeComplexity: codeQualityScore,
        maintainabilityIndex: codeQualityScore,
        testCoverage: 0, // Would need actual test analysis
        duplicationRatio: 0,
        lintScore: codeQualityScore,
        typeScriptErrors: 0
      },
      security: {
        vulnerabilityCount: 0, // Would need security scanning
        securityScore: 85,
        owaspCompliance: 80,
        dependencyVulnerabilities: 0,
        secretsExposed: 0,
        securityHeaders: 75
      },
      timeToCompletion: pipelineResult.totalDuration,
      agentic,
      resourceUsage: {
        maxMemoryUsage: Math.round(process.memoryUsage().heapTotal / (1024 * 1024)),
        avgCpuUsage: 0,
        diskIO: 0,
        networkIO: 0,
        buildTime: 0,
        deploymentTime: 0
      },
      phaseMetrics: pipelineResult.phases.map(phase => ({
        phase: this.mapStandardPhaseToLegacy(phase.phase),
        duration: phase.metadata.duration,
        success: phase.success,
        outputQuality: phase.success ? 85 : 0,
        resourceUsage: {
          maxMemoryUsage: 0,
          avgCpuUsage: 0,
          diskIO: 0,
          networkIO: 0,
          buildTime: 0,
          deploymentTime: 0
        },
        errors: phase.errors?.map(err => err.message) || []
      }))
    };
  }

  /**
   * Generate comprehensive benchmark report with enhanced analytics
   */
  private async generateComprehensiveReport(results: BenchmarkResult[]): Promise<void> {
    try {
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      
      // Enhanced report data with analytics
      const reportData: EnhancedReportData = {
        metadata: {
          timestamp: new Date().toISOString(),
          totalProblems: results.length,
          successfulRuns: results.filter(r => r.success).length,
          failedRuns: results.filter(r => !r.success).length,
          averageScore: results.length > 0 ? results.reduce((sum, r) => sum + r.metrics.overallScore, 0) / results.length : 0,
          totalExecutionTime: results.reduce((sum, r) => sum + r.executionDetails.totalDuration, 0),
          framework: 'AE Framework v1.0.0 (Standardized Pipeline)',
          benchmarkVersion: 'req2run-benchmark',
          pipelineVersion: '1.0.0',
          agentsUsed: ['IntentAgentAdapter', 'RequirementsAgentAdapter', 'UserStoriesAgentAdapter', 'ValidationAgentAdapter', 'DomainModelingAgentAdapter', 'UIUXAgentAdapter']
        },
        configuration: this.config,
        analytics: this.generateAnalytics(results),
        results: results.map(result => ({
          problemId: result.problemId,
          success: result.success,
          score: result.metrics.overallScore,
          executionTime: result.executionDetails.totalDuration,
          agentic: result.metrics.agentic ?? null,
          functionalCoverage: result.metrics.functionalCoverage,
          phases: result.executionDetails.phaseExecutions.map(pe => ({
            phase: pe.phase,
            duration: pe.duration,
            success: pe.success,
            errors: pe.errors?.length || 0
          })),
          errors: result.errors?.map(e => e.message) || []
        }))
      };

      // Save reports
      const rawDir = (this.config?.reporting?.destinations?.[0]?.config as any)?.['directory'];
      const reportDir = (typeof rawDir === 'string' && rawDir.trim()) ? rawDir : 'reports/benchmark';
      await fs.mkdir(reportDir, { recursive: true });

      // Enhanced JSON report
      const jsonReportPath = `${reportDir}/req2run-standardized-benchmark-${timestamp}.json`;
      await fs.writeFile(jsonReportPath, JSON.stringify(reportData, null, 2));

      // Enhanced Markdown report
      const markdownReport = generateEnhancedMarkdownReport(reportData);
      const mdReportPath = `${reportDir}/req2run-standardized-benchmark-${timestamp}.md`;
      await fs.writeFile(mdReportPath, markdownReport);

      // CSV export for analysis
      const csvReport = generateCSVReport(results);
      const csvReportPath = `${reportDir}/req2run-standardized-benchmark-${timestamp}.csv`;
      await fs.writeFile(csvReportPath, csvReport);

      console.log(`üìä Enhanced Standardized Benchmark Reports Generated:`);
      console.log(`   üìÑ JSON Report: ${jsonReportPath}`);
      console.log(`   üìù Markdown Report: ${mdReportPath}`);
      console.log(`   üìà CSV Export: ${csvReportPath}`);

    } catch (error) {
      console.error('‚ùå Failed to generate comprehensive report:', error);
    }
  }

  // Helper methods
  private buildDescription(spec: unknown): string {
    const s = spec as MinimalSpec;
    let description = s.notes || s.title || 'Benchmark problem';
    
    if (s.category) description += `\n\nCategory: ${s.category}`;
    if (s.difficulty) description += `\nDifficulty: ${s.difficulty}`;
    if (s.estimated_time_minutes) description += `\nEstimated time: ${s.estimated_time_minutes} minutes`;

    return description;
  }

  private extractRequirements(spec: unknown): string[] {
    const requirements: string[] = [];
    const s = spec as MinimalSpec;

    // Extract functional requirements as plain descriptions
    const func: FunctionalReq[] = Array.isArray(s.requirements?.functional)
      ? (s.requirements?.functional as FunctionalReq[])
      : [];
    for (const req of func) {
      if (typeof req?.description === 'string' && req.description.trim().length > 0) {
        requirements.push(req.description.trim());
      }
    }

    // Extract non-functional requirements as plain descriptions
    const nfr: NonFunctionalRequirements = (s.requirements?.non_functional ?? {}) as NonFunctionalRequirements;
    for (const [, reqs] of Object.entries(nfr)) {
      if (Array.isArray(reqs)) {
        for (const req of reqs) {
          const desc = typeof req === 'string' ? req : req?.description ?? String(req);
          if (desc && String(desc).trim().length > 0) {
            requirements.push(String(desc).trim());
          }
        }
      }
    }

    return requirements;
  }

  private extractConstraints(spec: unknown): Record<string, unknown> {
    const s = spec as MinimalSpec;
    return {
      technical: s.constraints?.allowed_packages || [],
      business: s.constraints?.disallowed_packages || [],
      performance: (s.requirements?.non_functional as Record<string, unknown> | undefined)?.['performance'] || {},
      security: (s.requirements?.non_functional as Record<string, unknown> | undefined)?.['security'] || {},
      platform: s.constraints?.platform || []
    };
  }

  private buildSpecificationContent(spec: RequirementSpec): string {
    let content = `${spec.title}\n\n${spec.description}\n\n`;

    content += 'Requirements:\n';
    spec.requirements.forEach((req) => {
      content += `- HIGH: ${req}\n`;
    });

    if (spec.constraints) {
      content += '\nConstraints:\n';
      Object.entries(spec.constraints).forEach(([type, constraint]) => {
        content += `- ${type}: ${Array.isArray(constraint) ? constraint.join(', ') : JSON.stringify(constraint)}\n`;
      });
    }

    return content;
  }

  private mapStandardPhaseToLegacy(standardPhase: string): AEFrameworkPhase {
    const mapping: Record<string, AEFrameworkPhase> = {
      'intent': AEFrameworkPhase.INTENT_ANALYSIS,
      'requirements': AEFrameworkPhase.REQUIREMENTS,
      'user-stories': AEFrameworkPhase.USER_STORIES,
      'validation': AEFrameworkPhase.VALIDATION,
      'domain-modeling': AEFrameworkPhase.DOMAIN_MODELING,
      'ui-ux-generation': AEFrameworkPhase.UI_UX_GENERATION
    };
    
    return mapping[standardPhase] || AEFrameworkPhase.INTENT_ANALYSIS;
  }

  private extractPhaseInput(phase: PhaseResult<unknown>): unknown {
    // Extract relevant input information for reporting
    return {
      phase: phase.phase,
      timestamp: phase.metadata.startTime,
      confidence: phase.metadata.confidence
    };
  }

  private async extractGeneratedArtifacts(pipelineResult: PipelineResult): Promise<GeneratedArtifacts> {
    // Gate by config: optionally disable artifact generation
    if (!this.config?.evaluation?.generateArtifacts) {
      return { sourceCode: [], documentation: [], tests: [], configuration: [], deployment: [] };
    }

    // Extract artifacts from UI/UX generation phase
    const uiPhase = pipelineResult.phases.find(p => p.phase === 'ui-ux-generation');
    const docs = this.generateDocumentationFromPipeline(pipelineResult);

    // Add phase summary document for PM aggregation (#923 groundwork)
    const phaseSummary = [
      '# AE Framework Benchmark Artifacts (Standardized Pipeline)',
      '',
      '## Phase Summary',
      ...pipelineResult.phases.map(p => `- ${p.phase}: ${p.success ? '‚úÖ success' : '‚ùå fail'} (${p.metadata.duration}ms)`)
    ].join('\n');
    docs.push({ filename: 'phase-summary.md', content: phaseSummary, type: 'architecture', format: 'markdown' });

    // Include final output snapshot for traceability
    const finalPhase = pipelineResult.phases[pipelineResult.phases.length - 1];
    const finalData = finalPhase?.data ?? null;
    docs.push({
      filename: 'application-output.json',
      content: (() => { try { return JSON.stringify(finalData, null, 2); } catch { return String(finalData); } })(),
      type: 'api',
      format: 'markdown'
    });

    if (uiPhase && uiPhase.success) {
      const uiOutput = uiPhase.data as UIUXOutput;
      return {
        sourceCode: this.generateSourceCodeFromUI(uiOutput),
        documentation: docs,
        tests: [], // Would be generated based on validation phase
        configuration: this.generateConfigurationFiles(uiOutput),
        deployment: [] // Would be generated based on requirements
      };
    }

    return {
      sourceCode: [],
      documentation: docs,
      tests: [],
      configuration: [],
      deployment: []
    };
  }

  private generateSourceCodeFromUI(uiOutput: UIUXOutput): import('../types/index.js').SourceCodeArtifact[] {
    return uiOutput.components.map(component => ({
      filename: `src/components/${component.name}.tsx`,
      content: this.generateComponentCode(component),
      language: 'typescript',
      size: this.generateComponentCode(component).length,
      linesOfCode: this.generateComponentCode(component).split('\n').length
    }));
  }

  private generateComponentCode(component: UIComponent): string {
    return `// Generated component: ${component.name}
import React from 'react';

interface ${component.name}Props {
${component.props.map((prop) => `  ${prop.name}${prop.required ? '' : '?'}: ${prop.type};`).join('\n')}
}

export const ${component.name}: React.FC<${component.name}Props> = (props) => {
  return (
    <div className="${component.name.toLowerCase()}">
      {/* Component implementation */}
    </div>
  );
};
`;
  }

  private generateDocumentationFromPipeline(pipelineResult: PipelineResult): import('../types/index.js').DocumentationArtifact[] {
    return [
      {
        filename: 'README.md',
        content: this.generateREADME(pipelineResult),
        type: 'readme',
        format: 'markdown'
      }
    ];
  }

  private generateREADME(pipelineResult: PipelineResult): string {
    return `# Generated Application

This application was generated using the AE Framework standardized pipeline.

## Pipeline Execution Summary
- **Total Duration**: ${pipelineResult.totalDuration}ms
- **Phases Completed**: ${pipelineResult.phases.length}/6
- **Success**: ${pipelineResult.success ? 'Yes' : 'No'}

## Architecture

${pipelineResult.phases.map(phase => 
  `### ${phase.phase.charAt(0).toUpperCase() + phase.phase.slice(1)} Phase
- Duration: ${phase.metadata.duration}ms
- Success: ${phase.success}
- Confidence: ${phase.metadata.confidence || 'N/A'}`
).join('\n\n')}

## Getting Started

1. Install dependencies
2. Run the application
3. Access the user interface

Generated on: ${new Date().toISOString()}
`;
  }

  private generateConfigurationFiles(uiOutput: UIUXOutput): import('../types/index.js').ConfigurationArtifact[] {
    return [
      {
        filename: 'package.json',
        content: JSON.stringify({
          name: 'generated-application',
          version: '1.0.0',
          dependencies: {
            'react': '^18.0.0',
            'typescript': '^5.0.0'
          }
        }, null, 2),
        type: 'package'
      }
    ];
  }

  private assessFunctionalCoverage(output: unknown, spec: RequirementSpec): number {
    // Assess how well the generated output covers the functional requirements
    const totalRequirements = spec.requirements.length;
    if (totalRequirements === 0) return 100;

    // Simple heuristic: if we have UI components and user flows, assume good coverage
    if (this.isUIUXOutputLike(output)) {
      const componentCount = output.components.length;
      const flowCount = output.userFlows.length;
      return Math.min(100, (componentCount + flowCount) * 10);
    }

    return 50; // Base coverage for successful pipeline execution
  }

  private assessCodeQuality(output: unknown): number {
    // Assess code quality based on generated artifacts
    const o = output as { components?: Array<{ states?: unknown[] }>; designSystem?: { components?: unknown } };
    if (o.components && o.designSystem) {
      let score = 70; // Base quality score
      
      // Bonus for design system
      if (o.designSystem.components) score += 10;
      
      // Bonus for component states and interactions
      const componentsWithStates = o.components.filter((c) => Array.isArray(c.states) && c.states.length > 0);
      score += Math.min(20, componentsWithStates.length * 5);
      
      return Math.min(100, score);
    }
    
    return 60;
  }

  private calculatePerformanceScore(pipelineResult: PipelineResult): number {
    // Base performance calculation on execution time and success rate
    const avgPhaseTime = pipelineResult.totalDuration / pipelineResult.phases.length;
    const successfulPhases = pipelineResult.phases.filter(p => p.success).length;
    
    let score = (successfulPhases / pipelineResult.phases.length) * 100;
    
    // Penalty for slow execution (>5 seconds per phase)
    if (avgPhaseTime > 5000) {
      score *= 0.8;
    }
    
    return Math.min(100, score);
  }

  private calculateThroughput(pipelineResult: PipelineResult): number {
    // Calculate data throughput (phases per second)
    return pipelineResult.phases.length / (pipelineResult.totalDuration / 1000);
  }

  private generateAnalytics(results: BenchmarkResult[]): AnalyticsData {
    return generateAnalytics(results);
  }

  // Narrow unknown outputs coming from pipeline to the bits we need
  private isUIUXOutputLike(output: unknown): output is Pick<UIUXOutput, 'components' | 'userFlows'> {
    if (!output || typeof output !== 'object') return false;
    const o = output as Partial<UIUXOutput>;
    const hasComponents = Array.isArray(o.components);
    const hasFlows = Array.isArray(o.userFlows);
    return hasComponents && hasFlows;
  }

  private buildErrorResult(error: unknown, problemId: string, startTime: Date): BenchmarkResult {
    const endTime = new Date();
    const benchmarkError: BenchmarkError = {
      phase: AEFrameworkPhase.INTENT_ANALYSIS,
      type: 'runtime',
      message: error instanceof Error ? error.message : 'Unknown benchmark error',
      ...(error instanceof Error && error.stack ? { stack: error.stack } : {}),
      timestamp: new Date()
    };

    return {
      problemId,
      timestamp: endTime,
      success: false,
      metrics: this.getDefaultMetrics(),
      executionDetails: {
        startTime,
        endTime,
        totalDuration: endTime.getTime() - startTime.getTime(),
        phaseExecutions: [],
        environment: this.getSimpleEnvironment(),
        logs: []
      },
      generatedArtifacts: this.initializeArtifacts(),
      errors: [benchmarkError]
    };
  }

  private async getExecutionEnvironment(): Promise<ExecutionDetails['environment']> {
    return {
      nodeVersion: process.version,
      platform: process.platform,
      arch: process.arch,
      memory: process.memoryUsage().heapTotal,
      cpuCount: os.cpus().length
    };
  }

  private getSimpleEnvironment(): ExecutionDetails['environment'] {
    return {
      nodeVersion: process.version,
      platform: process.platform,
      arch: process.arch,
      memory: process.memoryUsage().heapTotal,
      cpuCount: os.cpus().length
    };
  }

  private initializeArtifacts(): GeneratedArtifacts {
    return {
      sourceCode: [],
      documentation: [],
      tests: [],
      configuration: [],
      deployment: []
    };
  }

  private getDefaultMetrics(): BenchmarkMetrics {
    return {
      overallScore: 0,
      functionalCoverage: 0,
      testPassRate: 0,
      performance: {
        responseTime: 0,
        throughput: 0,
        memoryUsage: process.memoryUsage().heapUsed,
        cpuUsage: 0,
        diskUsage: 0
      },
      codeQuality: {
        codeComplexity: 0,
        maintainabilityIndex: 0,
        testCoverage: 0,
        duplicationRatio: 0,
        lintScore: 0,
        typeScriptErrors: 0
      },
      security: {
        vulnerabilityCount: 0,
        securityScore: 0,
        owaspCompliance: 0,
        dependencyVulnerabilities: 0,
        secretsExposed: 0,
        securityHeaders: 0
      },
      timeToCompletion: 0,
      resourceUsage: {
        maxMemoryUsage: 0,
        avgCpuUsage: 0,
        diskIO: 0,
        networkIO: 0,
        buildTime: 0,
        deploymentTime: 0
      },
      phaseMetrics: []
    };
  }

  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize));
    }
    return chunks;
  }
}
